Timer unit: 1e-06 s

Total time: 645.224 s
File: /mnt/sdc1/yanleizhang/workspace/pytorch_projects/ssd.pytorch/layers/modules/multibox_loss.py
Function: forward at line 48

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    48                                               @profile
    49                                               def forward(self, predictions, targets):
    50                                                   """Multibox Loss
    51                                                   Args:
    52                                                       predictions (tuple): A tuple containing loc preds, conf preds,
    53                                                       and prior boxes from SSD net.
    54                                                           conf shape: torch.size(batch_size,num_priors,num_classes)
    55                                                           loc shape: torch.size(batch_size,num_priors,4)
    56                                                           priors shape: torch.size(num_priors,4)
    57                                           
    58                                                       targets (tensor): Ground truth boxes and labels for a batch,
    59                                                           shape: [batch_size,num_objs,5] (last idx is the label).
    60                                                   """
    61      1000       2513.0      2.5      0.0          loc_data, conf_data, priors = predictions
    62      1000      10816.0     10.8      0.0          num = loc_data.size(0)
    63      1000      62249.0     62.2      0.0          priors = priors[:loc_data.size(1), :]
    64      1000       6010.0      6.0      0.0          num_priors = (priors.size(0))
    65      1000       2242.0      2.2      0.0          num_classes = self.num_classes
    66                                           
    67                                                   # match priors (default boxes) and ground truth boxes
    68      1000      51172.0     51.2      0.0          loc_t = torch.Tensor(num, num_priors, 4)
    69      1000     159307.0    159.3      0.0          conf_t = torch.LongTensor(num, num_priors)
    70     32975     157985.0      4.8      0.0          for idx in range(num):
    71     31975    2011222.0     62.9      0.3              truths = targets[idx][:, :-1].data
    72     31975     793116.0     24.8      0.1              labels = targets[idx][:, -1].data
    73     31975      70457.0      2.2      0.0              defaults = priors.data
    74     31975     102992.0      3.2      0.0              match(self.threshold, truths, defaults, self.variance, labels,
    75     31975  611741784.0  19131.9     94.8                    loc_t, conf_t, idx)
    76      1000       3246.0      3.2      0.0          if self.use_gpu:
    77      1000      63771.0     63.8      0.0              loc_t = loc_t.cuda()
    78      1000     788424.0    788.4      0.1              conf_t = conf_t.cuda()
    79                                                   # wrap targets
    80      1000      16207.0     16.2      0.0          loc_t = Variable(loc_t, requires_grad=False)
    81      1000       9075.0      9.1      0.0          conf_t = Variable(conf_t, requires_grad=False)
    82                                           
    83      1000      65192.0     65.2      0.0          pos = conf_t > 0
    84      1000      40890.0     40.9      0.0          num_pos = pos.sum(dim=1, keepdim=True)
    85                                           
    86                                                   # Localization Loss (Smooth L1)
    87                                                   # Shape: [batch,num_priors,4]
    88      1000      55611.0     55.6      0.0          pos_idx = pos.unsqueeze(pos.dim()).expand_as(loc_data)
    89      1000    1570655.0   1570.7      0.2          loc_p = loc_data[pos_idx].view(-1, 4)
    90      1000    2410193.0   2410.2      0.4          loc_t = loc_t[pos_idx].view(-1, 4)
    91      1000    6562396.0   6562.4      1.0          loss_l = F.smooth_l1_loss(loc_p, loc_t, size_average=False)
    92                                           
    93                                                   # Compute max conf across batch for hard negative mining
    94      1000      30024.0     30.0      0.0          batch_conf = conf_data.view(-1, self.num_classes)
    95      1000    2495788.0   2495.8      0.4          loss_c = log_sum_exp(batch_conf) - \
    96      1000      88400.0     88.4      0.0              batch_conf.gather(1, conf_t.view(-1, 1))
    97                                           
    98                                                   # Hard Negative Mining
    99      1000     187690.0    187.7      0.0          loss_c[pos] = 0  # filter out pos boxes for now
   100      1000      16044.0     16.0      0.0          loss_c = loss_c.view(num, -1)
   101      1000     653111.0    653.1      0.1          _, loss_idx = loss_c.sort(1, descending=True)
   102      1000     546732.0    546.7      0.1          _, idx_rank = loss_idx.sort(1)
   103      1000     200749.0    200.7      0.0          num_pos = pos.long().sum(1, keepdim=True)
   104      1000     131356.0    131.4      0.0          num_neg = torch.clamp(self.negpos_ratio * num_pos, max=pos.size(1) - 1)
   105      1000      60127.0     60.1      0.0          neg = idx_rank < num_neg.expand_as(idx_rank)
   106                                           
   107                                                   # Confidence Loss Including Positive and Negative Examples
   108      1000      22679.0     22.7      0.0          pos_idx = pos.unsqueeze(2).expand_as(conf_data)
   109      1000      12523.0     12.5      0.0          neg_idx = neg.unsqueeze(2).expand_as(conf_data)
   110      1000    8798682.0   8798.7      1.4          conf_p = conf_data[(pos_idx + neg_idx).gt(0)
   111      1000      44564.0     44.6      0.0                             ].view(-1, self.num_classes)
   112      1000    2937613.0   2937.6      0.5          targets_weighted = conf_t[(pos + neg).gt(0)]
   113      1000     139454.0    139.5      0.0          loss_c = F.cross_entropy(conf_p, targets_weighted, size_average=False)
   114                                           
   115                                                   # Sum of losses: L(x,c,l,g) = (Lconf(x, c) + Î±Lloc(x,l,g)) / N
   116                                           
   117      1000    2041508.0   2041.5      0.3          N = num_pos.data.sum()
   118      1000      37734.0     37.7      0.0          loss_l /= N
   119      1000      19512.0     19.5      0.0          loss_c /= N
   120      1000       2017.0      2.0      0.0          return loss_l, loss_c

Total time: 0 s
File: /mnt/sdc1/yanleizhang/workspace/pytorch_projects/ssd.pytorch/ssd.py
Function: forward at line 50

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    50                                               @profile
    51                                               def forward(self, x):
    52                                                   """Applies network layers and ops on input image(s) x.
    53                                           
    54                                                   Args:
    55                                                       x: input image or batch of images. Shape: [batch,3,300,300].
    56                                           
    57                                                   Return:
    58                                                       Depending on phase:
    59                                                       test:
    60                                                           Variable(tensor) of output class label predictions,
    61                                                           confidence score, and corresponding location predictions for
    62                                                           each object detected. Shape: [batch,topk,7]
    63                                           
    64                                                       train:
    65                                                           list of concat outputs from:
    66                                                               1: confidence layers, Shape: [batch*num_priors,num_classes]
    67                                                               2: localization layers, Shape: [batch,num_priors*4]
    68                                                               3: priorbox layers, Shape: [2,num_priors*4]
    69                                                   """
    70                                                   sources = list()
    71                                                   loc = list()
    72                                                   conf = list()
    73                                           
    74                                                   # apply vgg up to conv4_3 relu
    75                                                   for k in range(23):
    76                                                       x = self.vgg[k](x)
    77                                           
    78                                                   s = self.L2Norm(x)
    79                                                   sources.append(s)
    80                                           
    81                                                   # apply vgg up to fc7
    82                                                   for k in range(23, len(self.vgg)):
    83                                                       x = self.vgg[k](x)
    84                                                   sources.append(x)
    85                                           
    86                                                   # apply extra layers and cache source layer outputs
    87                                                   for k, v in enumerate(self.extras):
    88                                                       x = F.relu(v(x), inplace=True)
    89                                                       if k % 2 == 1:
    90                                                           sources.append(x)
    91                                           
    92                                                   # apply multibox head to source layers
    93                                                   for (x, l, c) in zip(sources, self.loc, self.conf):
    94                                                       loc.append(l(x).permute(0, 2, 3, 1).contiguous())
    95                                                       conf.append(c(x).permute(0, 2, 3, 1).contiguous())
    96                                           
    97                                                   loc = torch.cat([o.view(o.size(0), -1) for o in loc], 1)
    98                                                   conf = torch.cat([o.view(o.size(0), -1) for o in conf], 1)
    99                                                   if self.phase == "test":
   100                                                       output = self.detect(
   101                                                           loc.view(loc.size(0), -1, 4),                   # loc preds
   102                                                           self.softmax(conf.view(conf.size(0), -1,
   103                                                                                  self.num_classes)),                # conf preds
   104                                                           self.priors.type(type(x.data))                  # default boxes
   105                                                       )
   106                                                   else:
   107                                                       output = (
   108                                                           loc.view(loc.size(0), -1, 4),
   109                                                           conf.view(conf.size(0), -1, self.num_classes),
   110                                                           self.priors
   111                                                       )
   112                                                   return output

Total time: 0 s
File: /mnt/sdc1/yanleizhang/workspace/pytorch_projects/ssd.pytorch/ssd.py
Function: load_weights at line 114

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   114                                               @profile
   115                                               def load_weights(self, base_file):
   116                                                   other, ext = os.path.splitext(base_file)
   117                                                   if ext == '.pkl' or '.pth':
   118                                                       print('Loading weights into state dict...')
   119                                                       self.load_state_dict(torch.load(base_file,
   120                                                                                       map_location=lambda storage, loc: storage))
   121                                                       print('Finished!')
   122                                                   else:
   123                                                       print('Sorry only .pth and .pkl files supported.')

Total time: 8.45598 s
File: /mnt/sdc1/yanleizhang/workspace/pytorch_projects/ssd.pytorch/ssd.py
Function: vgg at line 128

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   128                                           @profile
   129                                           def vgg(cfg, i, batch_norm=False):
   130         1          2.0      2.0      0.0      layers = []
   131         1          1.0      1.0      0.0      in_channels = i
   132        18         39.0      2.2      0.0      for v in cfg:
   133        17         23.0      1.4      0.0          if v == 'M':
   134         3        589.0    196.3      0.0              layers += [nn.MaxPool2d(kernel_size=2, stride=2)]
   135        14         13.0      0.9      0.0          elif v == 'C':
   136         1        106.0    106.0      0.0              layers += [nn.MaxPool2d(kernel_size=2, stride=2, ceil_mode=True)]
   137                                                   else:
   138        13    8442921.0 649455.5     99.8              conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)
   139        13         41.0      3.2      0.0              if batch_norm:
   140                                                           layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]
   141                                                       else:
   142        13       2489.0    191.5      0.0                  layers += [conv2d, nn.ReLU(inplace=True)]
   143        13         17.0      1.3      0.0              in_channels = v
   144         1        123.0    123.0      0.0      pool5 = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)
   145         1       7257.0   7257.0      0.1      conv6 = nn.Conv2d(512, 1024, kernel_size=3, padding=6, dilation=6)
   146         1       2072.0   2072.0      0.0      conv7 = nn.Conv2d(1024, 1024, kernel_size=1)
   147         1          2.0      2.0      0.0      layers += [pool5, conv6,
   148         1        282.0    282.0      0.0                 nn.ReLU(inplace=True), conv7, nn.ReLU(inplace=True)]
   149         1          1.0      1.0      0.0      return layers

Total time: 0.009645 s
File: /mnt/sdc1/yanleizhang/workspace/pytorch_projects/ssd.pytorch/ssd.py
Function: add_extras at line 152

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   152                                           @profile
   153                                           def add_extras(cfg, i, batch_norm=False):
   154                                               # Extra layers added to VGG for feature scaling
   155         1          2.0      2.0      0.0      layers = []
   156         1          1.0      1.0      0.0      in_channels = i
   157         1          2.0      2.0      0.0      flag = False
   158        11         41.0      3.7      0.4      for k, v in enumerate(cfg):
   159        10         24.0      2.4      0.2          if in_channels != 'S':
   160         8         14.0      1.8      0.1              if v == 'S':
   161         2          6.0      3.0      0.1                  layers += [nn.Conv2d(in_channels, cfg[k + 1],
   162         2       5322.0   2661.0     55.2                                       kernel_size=(1, 3)[flag], stride=2, padding=1)]
   163                                                       else:
   164         6       4177.0    696.2     43.3                  layers += [nn.Conv2d(in_channels, v, kernel_size=(1, 3)[flag])]
   165         8         34.0      4.2      0.4              flag = not flag
   166        10         20.0      2.0      0.2          in_channels = v
   167         1          2.0      2.0      0.0      return layers

Total time: 0.010564 s
File: /mnt/sdc1/yanleizhang/workspace/pytorch_projects/ssd.pytorch/ssd.py
Function: multibox at line 170

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   170                                           @profile
   171                                           def multibox(vgg, extra_layers, cfg, num_classes):
   172         1          3.0      3.0      0.0      loc_layers = []
   173         1          2.0      2.0      0.0      conf_layers = []
   174         1          3.0      3.0      0.0      vgg_source = [21, -2]
   175         3         11.0      3.7      0.1      for k, v in enumerate(vgg_source):
   176         2          8.0      4.0      0.1          loc_layers += [nn.Conv2d(vgg[v].out_channels,
   177         2       1493.0    746.5     14.1                                   cfg[k] * 4, kernel_size=3, padding=1)]
   178         2          9.0      4.5      0.1          conf_layers += [nn.Conv2d(vgg[v].out_channels,
   179         2       6166.0   3083.0     58.4                                    cfg[k] * num_classes, kernel_size=3, padding=1)]
   180         5         19.0      3.8      0.2      for k, v in enumerate(extra_layers[1::2], 2):
   181         4          7.0      1.8      0.1          loc_layers += [nn.Conv2d(v.out_channels, cfg[k]
   182         4       1040.0    260.0      9.8                                   * 4, kernel_size=3, padding=1)]
   183         4          7.0      1.8      0.1          conf_layers += [nn.Conv2d(v.out_channels, cfg[k]
   184         4       1795.0    448.8     17.0                                    * num_classes, kernel_size=3, padding=1)]
   185         1          1.0      1.0      0.0      return vgg, extra_layers, (loc_layers, conf_layers)

Total time: 8.49627 s
File: /mnt/sdc1/yanleizhang/workspace/pytorch_projects/ssd.pytorch/ssd.py
Function: build_ssd at line 203

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   203                                           @profile
   204                                           def build_ssd(phase, size=300, num_classes=21):
   205         1          2.0      2.0      0.0      if phase != "test" and phase != "train":
   206                                                   print("ERROR: Phase: " + phase + " not recognized")
   207                                                   return
   208         1          1.0      1.0      0.0      if size != 300:
   209                                                   print("ERROR: You specified size " + repr(size) + ". However, " +
   210                                                         "currently only SSD300 (size=300) is supported!")
   211                                                   return
   212         1    8456306.0 8456306.0     99.5      base_, extras_, head_ = multibox(vgg(base[str(size)], 3),
   213         1       9844.0   9844.0      0.1                                       add_extras(extras[str(size)], 1024),
   214         1      10669.0  10669.0      0.1                                       mbox[str(size)], num_classes)
   215         1      19446.0  19446.0      0.2      return SSD(phase, size, base_, extras_, head_, num_classes)

Total time: 0 s
File: /mnt/sdc1/yanleizhang/workspace/pytorch_projects/ssd.pytorch/utils/augmentations.py
Function: intersect at line 9

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
     9                                           @profile
    10                                           def intersect(box_a, box_b):
    11                                               max_xy = np.minimum(box_a[:, 2:], box_b[2:])
    12                                               min_xy = np.maximum(box_a[:, :2], box_b[:2])
    13                                               inter = np.clip((max_xy - min_xy), a_min=0, a_max=np.inf)
    14                                               return inter[:, 0] * inter[:, 1]

Total time: 0 s
File: /mnt/sdc1/yanleizhang/workspace/pytorch_projects/ssd.pytorch/utils/augmentations.py
Function: jaccard_numpy at line 17

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    17                                           @profile
    18                                           def jaccard_numpy(box_a, box_b):
    19                                               """Compute the jaccard overlap of two sets of boxes.  The jaccard overlap
    20                                               is simply the intersection over union of two boxes.
    21                                               E.g.:
    22                                                   A â© B / A âª B = A â© B / (area(A) + area(B) - A â© B)
    23                                               Args:
    24                                                   box_a: Multiple bounding boxes, Shape: [num_boxes,4]
    25                                                   box_b: Single bounding box, Shape: [4]
    26                                               Return:
    27                                                   jaccard overlap: Shape: [box_a.shape[0], box_a.shape[1]]
    28                                               """
    29                                               inter = intersect(box_a, box_b)
    30                                               area_a = ((box_a[:, 2] - box_a[:, 0]) *
    31                                                         (box_a[:, 3] - box_a[:, 1]))  # [A,B]
    32                                               area_b = ((box_b[2] - box_b[0]) *
    33                                                         (box_b[3] - box_b[1]))  # [A,B]
    34                                               union = area_a + area_b - inter
    35                                               return inter / union  # [A,B]

Total time: 0 s
File: /mnt/sdc1/yanleizhang/workspace/pytorch_projects/ssd.pytorch/utils/augmentations.py
Function: __call__ at line 52

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    52                                               @profile
    53                                               def __call__(self, img, boxes=None, labels=None):
    54                                                   for t in self.transforms:
    55                                                       img, boxes, labels = t(img, boxes, labels)
    56                                                   return img, boxes, labels

Total time: 0 s
File: /mnt/sdc1/yanleizhang/workspace/pytorch_projects/ssd.pytorch/utils/augmentations.py
Function: __call__ at line 66

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    66                                               @profile
    67                                               def __call__(self, img, boxes=None, labels=None):
    68                                                   return self.lambd(img, boxes, labels)

Total time: 0 s
File: /mnt/sdc1/yanleizhang/workspace/pytorch_projects/ssd.pytorch/utils/augmentations.py
Function: __call__ at line 72

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    72                                               @profile
    73                                               def __call__(self, image, boxes=None, labels=None):
    74                                                   return image.astype(np.float32), boxes, labels

Total time: 0 s
File: /mnt/sdc1/yanleizhang/workspace/pytorch_projects/ssd.pytorch/utils/augmentations.py
Function: __call__ at line 81

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    81                                               @profile
    82                                               def __call__(self, image, boxes=None, labels=None):
    83                                                   image = image.astype(np.float32)
    84                                                   image -= self.mean
    85                                                   return image.astype(np.float32), boxes, labels

Total time: 0 s
File: /mnt/sdc1/yanleizhang/workspace/pytorch_projects/ssd.pytorch/utils/augmentations.py
Function: __call__ at line 89

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    89                                               @profile
    90                                               def __call__(self, image, boxes=None, labels=None):
    91                                                   height, width, channels = image.shape
    92                                                   boxes[:, 0] *= width
    93                                                   boxes[:, 2] *= width
    94                                                   boxes[:, 1] *= height
    95                                                   boxes[:, 3] *= height
    96                                           
    97                                                   return image, boxes, labels

Total time: 0 s
File: /mnt/sdc1/yanleizhang/workspace/pytorch_projects/ssd.pytorch/utils/augmentations.py
Function: __call__ at line 101

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   101                                               @profile
   102                                               def __call__(self, image, boxes=None, labels=None):
   103                                                   height, width, channels = image.shape
   104                                                   boxes[:, 0] /= width
   105                                                   boxes[:, 2] /= width
   106                                                   boxes[:, 1] /= height
   107                                                   boxes[:, 3] /= height
   108                                           
   109                                                   return image, boxes, labels

Total time: 0 s
File: /mnt/sdc1/yanleizhang/workspace/pytorch_projects/ssd.pytorch/utils/augmentations.py
Function: __call__ at line 116

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   116                                               @profile
   117                                               def __call__(self, image, boxes=None, labels=None):
   118                                                   image = cv2.resize(image, (self.size,
   119                                                                              self.size))
   120                                                   return image, boxes, labels

Total time: 0 s
File: /mnt/sdc1/yanleizhang/workspace/pytorch_projects/ssd.pytorch/utils/augmentations.py
Function: __call__ at line 130

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   130                                               @profile
   131                                               def __call__(self, image, boxes=None, labels=None):
   132                                                   if random.randint(2):
   133                                                       image[:, :, 1] *= random.uniform(self.lower, self.upper)
   134                                           
   135                                                   return image, boxes, labels

Total time: 0 s
File: /mnt/sdc1/yanleizhang/workspace/pytorch_projects/ssd.pytorch/utils/augmentations.py
Function: __call__ at line 143

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   143                                               @profile
   144                                               def __call__(self, image, boxes=None, labels=None):
   145                                                   if random.randint(2):
   146                                                       image[:, :, 0] += random.uniform(-self.delta, self.delta)
   147                                                       image[:, :, 0][image[:, :, 0] > 360.0] -= 360.0
   148                                                       image[:, :, 0][image[:, :, 0] < 0.0] += 360.0
   149                                                   return image, boxes, labels

Total time: 0 s
File: /mnt/sdc1/yanleizhang/workspace/pytorch_projects/ssd.pytorch/utils/augmentations.py
Function: __call__ at line 158

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   158                                               @profile
   159                                               def __call__(self, image, boxes=None, labels=None):
   160                                                   if random.randint(2):
   161                                                       swap = self.perms[random.randint(len(self.perms))]
   162                                                       shuffle = SwapChannels(swap)  # shuffle channels
   163                                                       image = shuffle(image)
   164                                                   return image, boxes, labels

Total time: 0 s
File: /mnt/sdc1/yanleizhang/workspace/pytorch_projects/ssd.pytorch/utils/augmentations.py
Function: __call__ at line 172

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   172                                               @profile
   173                                               def __call__(self, image, boxes=None, labels=None):
   174                                                   if self.current == 'BGR' and self.transform == 'HSV':
   175                                                       image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
   176                                                   elif self.current == 'HSV' and self.transform == 'BGR':
   177                                                       image = cv2.cvtColor(image, cv2.COLOR_HSV2BGR)
   178                                                   else:
   179                                                       raise NotImplementedError
   180                                                   return image, boxes, labels

Total time: 0 s
File: /mnt/sdc1/yanleizhang/workspace/pytorch_projects/ssd.pytorch/utils/augmentations.py
Function: __call__ at line 190

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   190                                               @profile
   191                                               # expects float image
   192                                               def __call__(self, image, boxes=None, labels=None):
   193                                                   if random.randint(2):
   194                                                       alpha = random.uniform(self.lower, self.upper)
   195                                                       image *= alpha
   196                                                   return image, boxes, labels

Total time: 0 s
File: /mnt/sdc1/yanleizhang/workspace/pytorch_projects/ssd.pytorch/utils/augmentations.py
Function: __call__ at line 205

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   205                                               @profile
   206                                               def __call__(self, image, boxes=None, labels=None):
   207                                                   if random.randint(2):
   208                                                       delta = random.uniform(-self.delta, self.delta)
   209                                                       image += delta
   210                                                   return image, boxes, labels

Total time: 0 s
File: /mnt/sdc1/yanleizhang/workspace/pytorch_projects/ssd.pytorch/utils/augmentations.py
Function: __call__ at line 214

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   214                                               @profile
   215                                               def __call__(self, tensor, boxes=None, labels=None):
   216                                                   return tensor.cpu().numpy().astype(np.float32).transpose((1, 2, 0)), boxes, labels

Total time: 0 s
File: /mnt/sdc1/yanleizhang/workspace/pytorch_projects/ssd.pytorch/utils/augmentations.py
Function: __call__ at line 220

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   220                                               @profile
   221                                               def __call__(self, cvimage, boxes=None, labels=None):
   222                                                   return torch.from_numpy(cvimage.astype(np.float32)).permute(2, 0, 1), boxes, labels

Total time: 0 s
File: /mnt/sdc1/yanleizhang/workspace/pytorch_projects/ssd.pytorch/utils/augmentations.py
Function: __call__ at line 252

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   252                                               @profile
   253                                               def __call__(self, image, boxes=None, labels=None):
   254                                                   height, width, _ = image.shape
   255                                                   while True:
   256                                                       # randomly choose a mode
   257                                                       mode = random.choice(self.sample_options)
   258                                                       if mode is None:
   259                                                           return image, boxes, labels
   260                                           
   261                                                       min_iou, max_iou = mode
   262                                                       if min_iou is None:
   263                                                           min_iou = float('-inf')
   264                                                       if max_iou is None:
   265                                                           max_iou = float('inf')
   266                                           
   267                                                       # max trails (50)
   268                                                       for _ in range(50):
   269                                                           current_image = image
   270                                           
   271                                                           w = random.uniform(0.3 * width, width)
   272                                                           h = random.uniform(0.3 * height, height)
   273                                           
   274                                                           # aspect ratio constraint b/t .5 & 2
   275                                                           if h / w < 0.5 or h / w > 2:
   276                                                               continue
   277                                           
   278                                                           left = random.uniform(width - w)
   279                                                           top = random.uniform(height - h)
   280                                           
   281                                                           # convert to integer rect x1,y1,x2,y2
   282                                                           rect = np.array(
   283                                                               [int(left), int(top), int(left + w), int(top + h)])
   284                                           
   285                                                           # calculate IoU (jaccard overlap) b/t the cropped and gt boxes
   286                                                           overlap = jaccard_numpy(boxes, rect)
   287                                           
   288                                                           # is min and max overlap constraint satisfied? if not try again
   289                                                           if overlap.min() < min_iou and max_iou < overlap.max():
   290                                                               continue
   291                                           
   292                                                           # cut the crop from the image
   293                                                           current_image = current_image[rect[1]:rect[3], rect[0]:rect[2],
   294                                                                                         :]
   295                                           
   296                                                           # keep overlap with gt box IF center in sampled patch
   297                                                           centers = (boxes[:, :2] + boxes[:, 2:]) / 2.0
   298                                           
   299                                                           # mask in all gt boxes that above and to the left of centers
   300                                                           m1 = (rect[0] < centers[:, 0]) * (rect[1] < centers[:, 1])
   301                                           
   302                                                           # mask in all gt boxes that under and to the right of centers
   303                                                           m2 = (rect[2] > centers[:, 0]) * (rect[3] > centers[:, 1])
   304                                           
   305                                                           # mask in that both m1 and m2 are true
   306                                                           mask = m1 * m2
   307                                           
   308                                                           # have any valid boxes? try again if not
   309                                                           if not mask.any():
   310                                                               continue
   311                                           
   312                                                           # take only matching gt boxes
   313                                                           current_boxes = boxes[mask, :].copy()
   314                                           
   315                                                           # take only matching gt labels
   316                                                           current_labels = labels[mask]
   317                                           
   318                                                           # should we use the box left and top corner or the crop's
   319                                                           current_boxes[:, :2] = np.maximum(current_boxes[:, :2],
   320                                                                                             rect[:2])
   321                                                           # adjust to crop (by substracting crop's left,top)
   322                                                           current_boxes[:, :2] -= rect[:2]
   323                                           
   324                                                           current_boxes[:, 2:] = np.minimum(current_boxes[:, 2:],
   325                                                                                             rect[2:])
   326                                                           # adjust to crop (by substracting crop's left,top)
   327                                                           current_boxes[:, 2:] -= rect[:2]
   328                                           
   329                                                           return current_image, current_boxes, current_labels

Total time: 0 s
File: /mnt/sdc1/yanleizhang/workspace/pytorch_projects/ssd.pytorch/utils/augmentations.py
Function: __call__ at line 336

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   336                                               @profile
   337                                               def __call__(self, image, boxes, labels):
   338                                                   if random.randint(2):
   339                                                       return image, boxes, labels
   340                                           
   341                                                   height, width, depth = image.shape
   342                                                   ratio = random.uniform(1, 4)
   343                                                   left = random.uniform(0, width * ratio - width)
   344                                                   top = random.uniform(0, height * ratio - height)
   345                                           
   346                                                   expand_image = np.zeros(
   347                                                       (int(height * ratio), int(width * ratio), depth),
   348                                                       dtype=image.dtype)
   349                                                   expand_image[:, :, :] = self.mean
   350                                                   expand_image[int(top):int(top + height),
   351                                                                int(left):int(left + width)] = image
   352                                                   image = expand_image
   353                                           
   354                                                   boxes = boxes.copy()
   355                                                   boxes[:, :2] += (int(left), int(top))
   356                                                   boxes[:, 2:] += (int(left), int(top))
   357                                           
   358                                                   return image, boxes, labels

Total time: 0 s
File: /mnt/sdc1/yanleizhang/workspace/pytorch_projects/ssd.pytorch/utils/augmentations.py
Function: __call__ at line 362

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   362                                               @profile
   363                                               def __call__(self, image, boxes, classes):
   364                                                   _, width, _ = image.shape
   365                                                   if random.randint(2):
   366                                                       image = image[:, ::-1]
   367                                                       boxes = boxes.copy()
   368                                                       boxes[:, 0::2] = width - boxes[:, 2::-2]
   369                                                   return image, boxes, classes

Total time: 0 s
File: /mnt/sdc1/yanleizhang/workspace/pytorch_projects/ssd.pytorch/utils/augmentations.py
Function: __call__ at line 383

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   383                                               @profile
   384                                               def __call__(self, image):
   385                                                   """
   386                                                   Args:
   387                                                       image (Tensor): image tensor to be transformed
   388                                                   Return:
   389                                                       a tensor with channels swapped according to swap
   390                                                   """
   391                                                   # if torch.is_tensor(image):
   392                                                   #     image = image.data.cpu().numpy()
   393                                                   # else:
   394                                                   #     image = np.array(image)
   395                                                   image = image[:, :, self.swaps]
   396                                                   return image

Total time: 0 s
File: /mnt/sdc1/yanleizhang/workspace/pytorch_projects/ssd.pytorch/utils/augmentations.py
Function: __call__ at line 412

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   412                                               @profile
   413                                               def __call__(self, image, boxes, labels):
   414                                                   im = image.copy()
   415                                                   im, boxes, labels = self.rand_brightness(im, boxes, labels)
   416                                                   if random.randint(2):
   417                                                       distort = Compose(self.pd[:-1])
   418                                                   else:
   419                                                       distort = Compose(self.pd[1:])
   420                                                   im, boxes, labels = distort(im, boxes, labels)
   421                                                   return self.rand_light_noise(im, boxes, labels)

Total time: 0.000124 s
File: /mnt/sdc1/yanleizhang/workspace/pytorch_projects/ssd.pytorch/utils/augmentations.py
Function: __init__ at line 425

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   425                                               @profile
   426                                               def __init__(self, size=300, mean=(104, 117, 123)):
   427         1          2.0      2.0      1.6          self.mean = mean
   428         1          1.0      1.0      0.8          self.size = size
   429         1          1.0      1.0      0.8          self.augment = Compose([
   430         1          2.0      2.0      1.6              ConvertFromInts(),
   431         1          2.0      2.0      1.6              ToAbsoluteCoords(),
   432         1         58.0     58.0     46.8              PhotometricDistort(),
   433         1          6.0      6.0      4.8              Expand(self.mean),
   434         1          8.0      8.0      6.5              RandomSampleCrop(),
   435         1          1.0      1.0      0.8              RandomMirror(),
   436         1          1.0      1.0      0.8              ToPercentCoords(),
   437         1          6.0      6.0      4.8              Resize(self.size),
   438         1         36.0     36.0     29.0              SubtractMeans(self.mean)
   439                                                   ])

Total time: 0 s
File: /mnt/sdc1/yanleizhang/workspace/pytorch_projects/ssd.pytorch/utils/augmentations.py
Function: __call__ at line 441

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   441                                               @profile
   442                                               def __call__(self, img, boxes, labels):
   443                                                   return self.augment(img, boxes, labels)

Total time: 1428.76 s
File: train.py
Function: train at line 71

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    71                                           @profile
    72                                           def train():
    73         1          7.0      7.0      0.0      if args.dataset == 'COCO':
    74                                                   if args.dataset_root == VOC_ROOT:
    75                                                       if not os.path.exists(COCO_ROOT):
    76                                                           parser.error('Must specify dataset_root if specifying dataset')
    77                                                       print("WARNING: Using default COCO dataset_root because " +
    78                                                             "--dataset_root was not specified.")
    79                                                       args.dataset_root = COCO_ROOT
    80                                                   cfg = coco
    81                                                   dataset = COCODetection(root=args.dataset_root,
    82                                                                           transform=SSDAugmentation(cfg['min_dim'],
    83                                                                                                     MEANS))
    84         1          4.0      4.0      0.0      elif args.dataset == 'VOC':
    85         1          4.0      4.0      0.0          if args.dataset_root == COCO_ROOT:
    86                                                       parser.error('Must specify dataset if specifying dataset_root')
    87         1          4.0      4.0      0.0          cfg = voc
    88         1          3.0      3.0      0.0          dataset = VOCDetection(root=args.dataset_root,
    89         1          4.0      4.0      0.0                                 transform=SSDAugmentation(cfg['min_dim'],
    90         1      31865.0  31865.0      0.0                                                           MEANS))
    91                                           
    92         1          7.0      7.0      0.0      if args.visdom:
    93                                                   import visdom
    94                                                   viz = visdom.Visdom()
    95                                           
    96         1    8496397.0 8496397.0      0.6      ssd_net = build_ssd('train', cfg['min_dim'], cfg['num_classes'])
    97         1          4.0      4.0      0.0      net = ssd_net
    98                                           
    99         1          3.0      3.0      0.0      if args.cuda:
   100         1        305.0    305.0      0.0          net = torch.nn.DataParallel(ssd_net)
   101         1         16.0     16.0      0.0          cudnn.benchmark = False
   102                                           
   103         1         25.0     25.0      0.0      if args.resume:
   104                                                   print('Resuming training, loading {}...'.format(args.resume))
   105                                                   ssd_net.load_weights(args.resume)
   106                                               else:
   107         1    1121647.0 1121647.0      0.1          vgg_weights = torch.load(args.save_folder + args.basenet)
   108         1         77.0     77.0      0.0          print('Loading base network...')
   109         1     133077.0 133077.0      0.0          ssd_net.vgg.load_state_dict(vgg_weights)
   110                                           
   111         1          7.0      7.0      0.0      if args.cuda:
   112         1       1078.0   1078.0      0.0          net = net.cuda()
   113                                           
   114         1          4.0      4.0      0.0      if not args.resume:
   115         1         32.0     32.0      0.0          print('Initializing weights...')
   116                                                   # initialize newly added layers' weights with xavier method
   117         1        462.0    462.0      0.0          ssd_net.extras.apply(weights_init)
   118         1        220.0    220.0      0.0          ssd_net.loc.apply(weights_init)
   119         1        212.0    212.0      0.0          ssd_net.conf.apply(weights_init)
   120                                           
   121         1         10.0     10.0      0.0      optimizer = optim.SGD(net.parameters(), lr=args.lr, momentum=args.momentum,
   122         1        956.0    956.0      0.0                            weight_decay=args.weight_decay)
   123         1          5.0      5.0      0.0      criterion = MultiBoxLoss(cfg['num_classes'], 0.5, True, 0, True, 3, 0.5,
   124         1        146.0    146.0      0.0                               False, args.cuda)
   125                                           
   126         1        701.0    701.0      0.0      net.train()
   127                                               # loss counters
   128         1          2.0      2.0      0.0      loc_loss = 0
   129         1          2.0      2.0      0.0      conf_loss = 0
   130         1          2.0      2.0      0.0      epoch = 0
   131         1         23.0     23.0      0.0      print('Loading the dataset...')
   132                                           
   133         1         16.0     16.0      0.0      epoch_size = len(dataset) // args.batch_size
   134         1         11.0     11.0      0.0      print('Training SSD on:', dataset.name)
   135         1          7.0      7.0      0.0      print('Using the specified args:')
   136         1        111.0    111.0      0.0      print(args)
   137                                           
   138         1          3.0      3.0      0.0      step_index = 0
   139                                           
   140         1          3.0      3.0      0.0      if args.visdom:
   141                                                   vis_title = 'SSD.PyTorch on ' + dataset.name
   142                                                   vis_legend = ['Loc Loss', 'Conf Loss', 'Total Loss']
   143                                                   iter_plot = create_vis_plot('Iteration', 'Loss', vis_title, vis_legend)
   144                                                   epoch_plot = create_vis_plot('Epoch', 'Loss', vis_title, vis_legend)
   145                                           
   146         1          6.0      6.0      0.0      data_loader = data.DataLoader(dataset, args.batch_size,
   147         1          3.0      3.0      0.0                                    num_workers=args.num_workers,
   148         1          2.0      2.0      0.0                                    shuffle=True, collate_fn=detection_collate,
   149         1         48.0     48.0      0.0                                    pin_memory=True)
   150                                               # create batch iterator
   151         1     146906.0 146906.0      0.0      batch_iterator = iter(data_loader)
   152      1001       3936.0      3.9      0.0      for iteration in range(args.start_iter, cfg['max_iter']):
   153      1000       4871.0      4.9      0.0          if args.visdom and iteration != 0 and (iteration % epoch_size == 0):
   154                                                       update_vis_plot(epoch, loc_loss, conf_loss, epoch_plot, None,
   155                                                                       'append', epoch_size)
   156                                                       # reset epoch loss counters
   157                                                       loc_loss = 0
   158                                                       conf_loss = 0
   159                                                       epoch += 1
   160                                           
   161      1000       5429.0      5.4      0.0          if iteration in cfg['lr_steps']:
   162                                                       step_index += 1
   163                                                       adjust_learning_rate(optimizer, args.gamma, step_index)
   164                                           
   165                                                   # load train data
   166                                                   # images, targets = next(batch_iterator)
   167                                           
   168      1000       3278.0      3.3      0.0          try:
   169      1000    8378393.0   8378.4      0.6              images, targets = next(batch_iterator)
   170         1          4.0      4.0      0.0          except StopIteration:
   171         1    1711321.0 1711321.0      0.1              batch_iterator = iter(data_loader)
   172         1    8489110.0 8489110.0      0.6              images, targets = next(batch_iterator)
   173                                           
   174      1000       7852.0      7.9      0.0          if args.cuda:
   175      1000    7158885.0   7158.9      0.5              images = Variable(images.cuda())
   176      1000    2856915.0   2856.9      0.2              targets = [Variable(ann.cuda(), volatile=True) for ann in targets]
   177                                                   else:
   178                                                       images = Variable(images)
   179                                                       targets = [Variable(ann, volatile=True) for ann in targets]
   180                                                   # forward
   181      1000      23720.0     23.7      0.0          t0 = time.time()
   182      1000  222758903.0 222758.9     15.6          out = net(images)
   183                                                   # backprop
   184      1000     981366.0    981.4      0.1          optimizer.zero_grad()
   185      1000  645936512.0 645936.5     45.2          loss_l, loss_c = criterion(out, targets)
   186      1000    1336353.0   1336.4      0.1          loss = loss_l + loss_c
   187      1000   51729617.0  51729.6      3.6          loss.backward()
   188      1000    4142982.0   4143.0      0.3          optimizer.step()
   189      1000       9464.0      9.5      0.0          t1 = time.time()
   190      1000  462557862.0 462557.9     32.4          loc_loss += loss_l.data[0]
   191      1000     105653.0    105.7      0.0          conf_loss += loss_c.data[0]
   192                                           
   193      1000       5861.0      5.9      0.0          if iteration % 10 == 0:
   194       100      23520.0    235.2      0.0              print('timer: %.4f sec.' % (t1 - t0))
   195       100        755.0      7.5      0.0              print('iter ' + repr(iteration) + ' || Loss: %.4f ||' %
   196       100       5837.0     58.4      0.0                    (loss.data[0]), end=' ')
   197                                           
   198      1000      43192.0     43.2      0.0          if args.visdom:
   199                                                       update_vis_plot(iteration, loss_l.data[0], loss_c.data[0],
   200                                                                       iter_plot, epoch_plot, 'append')
   201                                           
   202      1000       3918.0      3.9      0.0          if iteration != 0 and iteration % 5000 == 0:
   203                                                       print('Saving state, iter:', iteration)
   204                                                       torch.save(ssd_net.state_dict(), 'weights/ssd300_COCO_' +
   205                                                                  repr(iteration) + '.pth')
   206         1       1149.0   1149.0      0.0      torch.save(ssd_net.state_dict(),
   207         1     539854.0 539854.0      0.0                 args.save_folder + '' + args.dataset + '.pth')

Total time: 0 s
File: train.py
Function: adjust_learning_rate at line 210

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   210                                           @profile
   211                                           def adjust_learning_rate(optimizer, gamma, step):
   212                                               """Sets the learning rate to the initial LR decayed by 10 at every
   213                                                   specified step
   214                                               # Adapted from PyTorch Imagenet example:
   215                                               # https://github.com/pytorch/examples/blob/master/imagenet/main.py
   216                                               """
   217                                               lr = args.lr * (gamma ** (step))
   218                                               for param_group in optimizer.param_groups:
   219                                                   param_group['lr'] = lr

