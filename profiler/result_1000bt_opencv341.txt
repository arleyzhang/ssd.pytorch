Timer unit: 1e-06 s

Total time: 536.919 s
File: /mnt/sdc1/yanleizhang/workspace/pytorch_projects/ssd.pytorch/layers/modules/multibox_loss.py
Function: forward at line 48

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    48                                               @profile
    49                                               def forward(self, predictions, targets):
    50                                                   """Multibox Loss
    51                                                   Args:
    52                                                       predictions (tuple): A tuple containing loc preds, conf preds,
    53                                                       and prior boxes from SSD net.
    54                                                           conf shape: torch.size(batch_size,num_priors,num_classes)
    55                                                           loc shape: torch.size(batch_size,num_priors,4)
    56                                                           priors shape: torch.size(num_priors,4)
    57                                           
    58                                                       targets (tensor): Ground truth boxes and labels for a batch,
    59                                                           shape: [batch_size,num_objs,5] (last idx is the label).
    60                                                   """
    61      1000       2462.0      2.5      0.0          loc_data, conf_data, priors = predictions
    62      1000      11544.0     11.5      0.0          num = loc_data.size(0)
    63      1000      62562.0     62.6      0.0          priors = priors[:loc_data.size(1), :]
    64      1000       5989.0      6.0      0.0          num_priors = (priors.size(0))
    65      1000       2285.0      2.3      0.0          num_classes = self.num_classes
    66                                           
    67                                                   # match priors (default boxes) and ground truth boxes
    68      1000      26530.0     26.5      0.0          loc_t = torch.Tensor(num, num_priors, 4)
    69      1000     106044.0    106.0      0.0          conf_t = torch.LongTensor(num, num_priors)
    70     32975     136651.0      4.1      0.0          for idx in range(num):
    71     31975    2265729.0     70.9      0.4              truths = targets[idx][:, :-1].data
    72     31975     920165.0     28.8      0.2              labels = targets[idx][:, -1].data
    73     31975      70434.0      2.2      0.0              defaults = priors.data
    74     31975     134524.0      4.2      0.0              match(self.threshold, truths, defaults, self.variance, labels,
    75     31975  506443485.0  15838.7     94.3                    loc_t, conf_t, idx)
    76      1000       3243.0      3.2      0.0          if self.use_gpu:
    77      1000      30614.0     30.6      0.0              loc_t = loc_t.cuda()
    78      1000     761629.0    761.6      0.1              conf_t = conf_t.cuda()
    79                                                   # wrap targets
    80      1000      14494.0     14.5      0.0          loc_t = Variable(loc_t, requires_grad=False)
    81      1000       7772.0      7.8      0.0          conf_t = Variable(conf_t, requires_grad=False)
    82                                           
    83      1000      78448.0     78.4      0.0          pos = conf_t > 0
    84      1000      51436.0     51.4      0.0          num_pos = pos.sum(dim=1, keepdim=True)
    85                                           
    86                                                   # Localization Loss (Smooth L1)
    87                                                   # Shape: [batch,num_priors,4]
    88      1000      82861.0     82.9      0.0          pos_idx = pos.unsqueeze(pos.dim()).expand_as(loc_data)
    89      1000    1359943.0   1359.9      0.3          loc_p = loc_data[pos_idx].view(-1, 4)
    90      1000    1936919.0   1936.9      0.4          loc_t = loc_t[pos_idx].view(-1, 4)
    91      1000    5197955.0   5198.0      1.0          loss_l = F.smooth_l1_loss(loc_p, loc_t, size_average=False)
    92                                           
    93                                                   # Compute max conf across batch for hard negative mining
    94      1000      32860.0     32.9      0.0          batch_conf = conf_data.view(-1, self.num_classes)
    95      1000    2278810.0   2278.8      0.4          loss_c = log_sum_exp(batch_conf) - \
    96      1000     117087.0    117.1      0.0              batch_conf.gather(1, conf_t.view(-1, 1))
    97                                           
    98                                                   # Hard Negative Mining
    99      1000     244357.0    244.4      0.0          loss_c[pos] = 0  # filter out pos boxes for now
   100      1000      25422.0     25.4      0.0          loss_c = loss_c.view(num, -1)
   101      1000     793147.0    793.1      0.1          _, loss_idx = loss_c.sort(1, descending=True)
   102      1000     685108.0    685.1      0.1          _, idx_rank = loss_idx.sort(1)
   103      1000     252438.0    252.4      0.0          num_pos = pos.long().sum(1, keepdim=True)
   104      1000     142554.0    142.6      0.0          num_neg = torch.clamp(self.negpos_ratio * num_pos, max=pos.size(1) - 1)
   105      1000      99236.0     99.2      0.0          neg = idx_rank < num_neg.expand_as(idx_rank)
   106                                           
   107                                                   # Confidence Loss Including Positive and Negative Examples
   108      1000      31310.0     31.3      0.0          pos_idx = pos.unsqueeze(2).expand_as(conf_data)
   109      1000      21200.0     21.2      0.0          neg_idx = neg.unsqueeze(2).expand_as(conf_data)
   110      1000    7845187.0   7845.2      1.5          conf_p = conf_data[(pos_idx + neg_idx).gt(0)
   111      1000      23585.0     23.6      0.0                             ].view(-1, self.num_classes)
   112      1000    2615497.0   2615.5      0.5          targets_weighted = conf_t[(pos + neg).gt(0)]
   113      1000     183333.0    183.3      0.0          loss_c = F.cross_entropy(conf_p, targets_weighted, size_average=False)
   114                                           
   115                                                   # Sum of losses: L(x,c,l,g) = (Lconf(x, c) + Î±Lloc(x,l,g)) / N
   116                                           
   117      1000    1743361.0   1743.4      0.3          N = num_pos.data.sum()
   118      1000      48910.0     48.9      0.0          loss_l /= N
   119      1000      19435.0     19.4      0.0          loss_c /= N
   120      1000       2112.0      2.1      0.0          return loss_l, loss_c

Total time: 0 s
File: /mnt/sdc1/yanleizhang/workspace/pytorch_projects/ssd.pytorch/ssd.py
Function: forward at line 50

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    50                                               @profile
    51                                               def forward(self, x):
    52                                                   """Applies network layers and ops on input image(s) x.
    53                                           
    54                                                   Args:
    55                                                       x: input image or batch of images. Shape: [batch,3,300,300].
    56                                           
    57                                                   Return:
    58                                                       Depending on phase:
    59                                                       test:
    60                                                           Variable(tensor) of output class label predictions,
    61                                                           confidence score, and corresponding location predictions for
    62                                                           each object detected. Shape: [batch,topk,7]
    63                                           
    64                                                       train:
    65                                                           list of concat outputs from:
    66                                                               1: confidence layers, Shape: [batch*num_priors,num_classes]
    67                                                               2: localization layers, Shape: [batch,num_priors*4]
    68                                                               3: priorbox layers, Shape: [2,num_priors*4]
    69                                                   """
    70                                                   sources = list()
    71                                                   loc = list()
    72                                                   conf = list()
    73                                           
    74                                                   # apply vgg up to conv4_3 relu
    75                                                   for k in range(23):
    76                                                       x = self.vgg[k](x)
    77                                           
    78                                                   s = self.L2Norm(x)
    79                                                   sources.append(s)
    80                                           
    81                                                   # apply vgg up to fc7
    82                                                   for k in range(23, len(self.vgg)):
    83                                                       x = self.vgg[k](x)
    84                                                   sources.append(x)
    85                                           
    86                                                   # apply extra layers and cache source layer outputs
    87                                                   for k, v in enumerate(self.extras):
    88                                                       x = F.relu(v(x), inplace=True)
    89                                                       if k % 2 == 1:
    90                                                           sources.append(x)
    91                                           
    92                                                   # apply multibox head to source layers
    93                                                   for (x, l, c) in zip(sources, self.loc, self.conf):
    94                                                       loc.append(l(x).permute(0, 2, 3, 1).contiguous())
    95                                                       conf.append(c(x).permute(0, 2, 3, 1).contiguous())
    96                                           
    97                                                   loc = torch.cat([o.view(o.size(0), -1) for o in loc], 1)
    98                                                   conf = torch.cat([o.view(o.size(0), -1) for o in conf], 1)
    99                                                   if self.phase == "test":
   100                                                       output = self.detect(
   101                                                           loc.view(loc.size(0), -1, 4),                   # loc preds
   102                                                           self.softmax(conf.view(conf.size(0), -1,
   103                                                                                  self.num_classes)),                # conf preds
   104                                                           self.priors.type(type(x.data))                  # default boxes
   105                                                       )
   106                                                   else:
   107                                                       output = (
   108                                                           loc.view(loc.size(0), -1, 4),
   109                                                           conf.view(conf.size(0), -1, self.num_classes),
   110                                                           self.priors
   111                                                       )
   112                                                   return output

Total time: 0 s
File: /mnt/sdc1/yanleizhang/workspace/pytorch_projects/ssd.pytorch/ssd.py
Function: load_weights at line 114

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   114                                               @profile
   115                                               def load_weights(self, base_file):
   116                                                   other, ext = os.path.splitext(base_file)
   117                                                   if ext == '.pkl' or '.pth':
   118                                                       print('Loading weights into state dict...')
   119                                                       self.load_state_dict(torch.load(base_file,
   120                                                                                       map_location=lambda storage, loc: storage))
   121                                                       print('Finished!')
   122                                                   else:
   123                                                       print('Sorry only .pth and .pkl files supported.')

Total time: 8.7891 s
File: /mnt/sdc1/yanleizhang/workspace/pytorch_projects/ssd.pytorch/ssd.py
Function: vgg at line 128

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   128                                           @profile
   129                                           def vgg(cfg, i, batch_norm=False):
   130         1          1.0      1.0      0.0      layers = []
   131         1          1.0      1.0      0.0      in_channels = i
   132        18         31.0      1.7      0.0      for v in cfg:
   133        17         23.0      1.4      0.0          if v == 'M':
   134         3        444.0    148.0      0.0              layers += [nn.MaxPool2d(kernel_size=2, stride=2)]
   135        14         15.0      1.1      0.0          elif v == 'C':
   136         1        185.0    185.0      0.0              layers += [nn.MaxPool2d(kernel_size=2, stride=2, ceil_mode=True)]
   137                                                   else:
   138        13    8771317.0 674716.7     99.8              conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)
   139        13         34.0      2.6      0.0              if batch_norm:
   140                                                           layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]
   141                                                       else:
   142        13       2131.0    163.9      0.0                  layers += [conv2d, nn.ReLU(inplace=True)]
   143        13         14.0      1.1      0.0              in_channels = v
   144         1        117.0    117.0      0.0      pool5 = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)
   145         1       5283.0   5283.0      0.1      conv6 = nn.Conv2d(512, 1024, kernel_size=3, padding=6, dilation=6)
   146         1       9340.0   9340.0      0.1      conv7 = nn.Conv2d(1024, 1024, kernel_size=1)
   147         1          2.0      2.0      0.0      layers += [pool5, conv6,
   148         1        166.0    166.0      0.0                 nn.ReLU(inplace=True), conv7, nn.ReLU(inplace=True)]
   149         1          1.0      1.0      0.0      return layers

Total time: 0.003179 s
File: /mnt/sdc1/yanleizhang/workspace/pytorch_projects/ssd.pytorch/ssd.py
Function: add_extras at line 152

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   152                                           @profile
   153                                           def add_extras(cfg, i, batch_norm=False):
   154                                               # Extra layers added to VGG for feature scaling
   155         1          1.0      1.0      0.0      layers = []
   156         1          1.0      1.0      0.0      in_channels = i
   157         1          1.0      1.0      0.0      flag = False
   158        11         16.0      1.5      0.5      for k, v in enumerate(cfg):
   159        10          9.0      0.9      0.3          if in_channels != 'S':
   160         8          4.0      0.5      0.1              if v == 'S':
   161         2          3.0      1.5      0.1                  layers += [nn.Conv2d(in_channels, cfg[k + 1],
   162         2       1622.0    811.0     51.0                                       kernel_size=(1, 3)[flag], stride=2, padding=1)]
   163                                                       else:
   164         6       1505.0    250.8     47.3                  layers += [nn.Conv2d(in_channels, v, kernel_size=(1, 3)[flag])]
   165         8         10.0      1.2      0.3              flag = not flag
   166        10          7.0      0.7      0.2          in_channels = v
   167         1          0.0      0.0      0.0      return layers

Total time: 0.011479 s
File: /mnt/sdc1/yanleizhang/workspace/pytorch_projects/ssd.pytorch/ssd.py
Function: multibox at line 170

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   170                                           @profile
   171                                           def multibox(vgg, extra_layers, cfg, num_classes):
   172         1          1.0      1.0      0.0      loc_layers = []
   173         1          1.0      1.0      0.0      conf_layers = []
   174         1          1.0      1.0      0.0      vgg_source = [21, -2]
   175         3          6.0      2.0      0.1      for k, v in enumerate(vgg_source):
   176         2          3.0      1.5      0.0          loc_layers += [nn.Conv2d(vgg[v].out_channels,
   177         2        470.0    235.0      4.1                                   cfg[k] * 4, kernel_size=3, padding=1)]
   178         2          3.0      1.5      0.0          conf_layers += [nn.Conv2d(vgg[v].out_channels,
   179         2       4339.0   2169.5     37.8                                    cfg[k] * num_classes, kernel_size=3, padding=1)]
   180         5         46.0      9.2      0.4      for k, v in enumerate(extra_layers[1::2], 2):
   181         4         10.0      2.5      0.1          loc_layers += [nn.Conv2d(v.out_channels, cfg[k]
   182         4       1465.0    366.2     12.8                                   * 4, kernel_size=3, padding=1)]
   183         4         10.0      2.5      0.1          conf_layers += [nn.Conv2d(v.out_channels, cfg[k]
   184         4       5122.0   1280.5     44.6                                    * num_classes, kernel_size=3, padding=1)]
   185         1          2.0      2.0      0.0      return vgg, extra_layers, (loc_layers, conf_layers)

Total time: 8.8275 s
File: /mnt/sdc1/yanleizhang/workspace/pytorch_projects/ssd.pytorch/ssd.py
Function: build_ssd at line 203

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   203                                           @profile
   204                                           def build_ssd(phase, size=300, num_classes=21):
   205         1          1.0      1.0      0.0      if phase != "test" and phase != "train":
   206                                                   print("ERROR: Phase: " + phase + " not recognized")
   207                                                   return
   208         1          1.0      1.0      0.0      if size != 300:
   209                                                   print("ERROR: You specified size " + repr(size) + ". However, " +
   210                                                         "currently only SSD300 (size=300) is supported!")
   211                                                   return
   212         1    8789349.0 8789349.0     99.6      base_, extras_, head_ = multibox(vgg(base[str(size)], 3),
   213         1       3253.0   3253.0      0.0                                       add_extras(extras[str(size)], 1024),
   214         1      11552.0  11552.0      0.1                                       mbox[str(size)], num_classes)
   215         1      23346.0  23346.0      0.3      return SSD(phase, size, base_, extras_, head_, num_classes)

Total time: 0 s
File: /mnt/sdc1/yanleizhang/workspace/pytorch_projects/ssd.pytorch/utils/augmentations.py
Function: intersect at line 9

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
     9                                           @profile
    10                                           def intersect(box_a, box_b):
    11                                               max_xy = np.minimum(box_a[:, 2:], box_b[2:])
    12                                               min_xy = np.maximum(box_a[:, :2], box_b[:2])
    13                                               inter = np.clip((max_xy - min_xy), a_min=0, a_max=np.inf)
    14                                               return inter[:, 0] * inter[:, 1]

Total time: 0 s
File: /mnt/sdc1/yanleizhang/workspace/pytorch_projects/ssd.pytorch/utils/augmentations.py
Function: jaccard_numpy at line 17

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    17                                           @profile
    18                                           def jaccard_numpy(box_a, box_b):
    19                                               """Compute the jaccard overlap of two sets of boxes.  The jaccard overlap
    20                                               is simply the intersection over union of two boxes.
    21                                               E.g.:
    22                                                   A â© B / A âª B = A â© B / (area(A) + area(B) - A â© B)
    23                                               Args:
    24                                                   box_a: Multiple bounding boxes, Shape: [num_boxes,4]
    25                                                   box_b: Single bounding box, Shape: [4]
    26                                               Return:
    27                                                   jaccard overlap: Shape: [box_a.shape[0], box_a.shape[1]]
    28                                               """
    29                                               inter = intersect(box_a, box_b)
    30                                               area_a = ((box_a[:, 2] - box_a[:, 0]) *
    31                                                         (box_a[:, 3] - box_a[:, 1]))  # [A,B]
    32                                               area_b = ((box_b[2] - box_b[0]) *
    33                                                         (box_b[3] - box_b[1]))  # [A,B]
    34                                               union = area_a + area_b - inter
    35                                               return inter / union  # [A,B]

Total time: 0 s
File: /mnt/sdc1/yanleizhang/workspace/pytorch_projects/ssd.pytorch/utils/augmentations.py
Function: __call__ at line 52

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    52                                               @profile
    53                                               def __call__(self, img, boxes=None, labels=None):
    54                                                   for t in self.transforms:
    55                                                       img, boxes, labels = t(img, boxes, labels)
    56                                                   return img, boxes, labels

Total time: 0 s
File: /mnt/sdc1/yanleizhang/workspace/pytorch_projects/ssd.pytorch/utils/augmentations.py
Function: __call__ at line 66

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    66                                               @profile
    67                                               def __call__(self, img, boxes=None, labels=None):
    68                                                   return self.lambd(img, boxes, labels)

Total time: 0 s
File: /mnt/sdc1/yanleizhang/workspace/pytorch_projects/ssd.pytorch/utils/augmentations.py
Function: __call__ at line 72

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    72                                               @profile
    73                                               def __call__(self, image, boxes=None, labels=None):
    74                                                   return image.astype(np.float32), boxes, labels

Total time: 0 s
File: /mnt/sdc1/yanleizhang/workspace/pytorch_projects/ssd.pytorch/utils/augmentations.py
Function: __call__ at line 81

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    81                                               @profile
    82                                               def __call__(self, image, boxes=None, labels=None):
    83                                                   image = image.astype(np.float32)
    84                                                   image -= self.mean
    85                                                   return image.astype(np.float32), boxes, labels

Total time: 0 s
File: /mnt/sdc1/yanleizhang/workspace/pytorch_projects/ssd.pytorch/utils/augmentations.py
Function: __call__ at line 89

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    89                                               @profile
    90                                               def __call__(self, image, boxes=None, labels=None):
    91                                                   height, width, channels = image.shape
    92                                                   boxes[:, 0] *= width
    93                                                   boxes[:, 2] *= width
    94                                                   boxes[:, 1] *= height
    95                                                   boxes[:, 3] *= height
    96                                           
    97                                                   return image, boxes, labels

Total time: 0 s
File: /mnt/sdc1/yanleizhang/workspace/pytorch_projects/ssd.pytorch/utils/augmentations.py
Function: __call__ at line 101

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   101                                               @profile
   102                                               def __call__(self, image, boxes=None, labels=None):
   103                                                   height, width, channels = image.shape
   104                                                   boxes[:, 0] /= width
   105                                                   boxes[:, 2] /= width
   106                                                   boxes[:, 1] /= height
   107                                                   boxes[:, 3] /= height
   108                                           
   109                                                   return image, boxes, labels

Total time: 0 s
File: /mnt/sdc1/yanleizhang/workspace/pytorch_projects/ssd.pytorch/utils/augmentations.py
Function: __call__ at line 116

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   116                                               @profile
   117                                               def __call__(self, image, boxes=None, labels=None):
   118                                                   image = cv2.resize(image, (self.size,
   119                                                                              self.size))
   120                                                   return image, boxes, labels

Total time: 0 s
File: /mnt/sdc1/yanleizhang/workspace/pytorch_projects/ssd.pytorch/utils/augmentations.py
Function: __call__ at line 130

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   130                                               @profile
   131                                               def __call__(self, image, boxes=None, labels=None):
   132                                                   if random.randint(2):
   133                                                       image[:, :, 1] *= random.uniform(self.lower, self.upper)
   134                                           
   135                                                   return image, boxes, labels

Total time: 0 s
File: /mnt/sdc1/yanleizhang/workspace/pytorch_projects/ssd.pytorch/utils/augmentations.py
Function: __call__ at line 143

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   143                                               @profile
   144                                               def __call__(self, image, boxes=None, labels=None):
   145                                                   if random.randint(2):
   146                                                       image[:, :, 0] += random.uniform(-self.delta, self.delta)
   147                                                       image[:, :, 0][image[:, :, 0] > 360.0] -= 360.0
   148                                                       image[:, :, 0][image[:, :, 0] < 0.0] += 360.0
   149                                                   return image, boxes, labels

Total time: 0 s
File: /mnt/sdc1/yanleizhang/workspace/pytorch_projects/ssd.pytorch/utils/augmentations.py
Function: __call__ at line 158

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   158                                               @profile
   159                                               def __call__(self, image, boxes=None, labels=None):
   160                                                   if random.randint(2):
   161                                                       swap = self.perms[random.randint(len(self.perms))]
   162                                                       shuffle = SwapChannels(swap)  # shuffle channels
   163                                                       image = shuffle(image)
   164                                                   return image, boxes, labels

Total time: 0 s
File: /mnt/sdc1/yanleizhang/workspace/pytorch_projects/ssd.pytorch/utils/augmentations.py
Function: __call__ at line 172

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   172                                               @profile
   173                                               def __call__(self, image, boxes=None, labels=None):
   174                                                   if self.current == 'BGR' and self.transform == 'HSV':
   175                                                       image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
   176                                                   elif self.current == 'HSV' and self.transform == 'BGR':
   177                                                       image = cv2.cvtColor(image, cv2.COLOR_HSV2BGR)
   178                                                   else:
   179                                                       raise NotImplementedError
   180                                                   return image, boxes, labels

Total time: 0 s
File: /mnt/sdc1/yanleizhang/workspace/pytorch_projects/ssd.pytorch/utils/augmentations.py
Function: __call__ at line 190

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   190                                               @profile
   191                                               # expects float image
   192                                               def __call__(self, image, boxes=None, labels=None):
   193                                                   if random.randint(2):
   194                                                       alpha = random.uniform(self.lower, self.upper)
   195                                                       image *= alpha
   196                                                   return image, boxes, labels

Total time: 0 s
File: /mnt/sdc1/yanleizhang/workspace/pytorch_projects/ssd.pytorch/utils/augmentations.py
Function: __call__ at line 205

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   205                                               @profile
   206                                               def __call__(self, image, boxes=None, labels=None):
   207                                                   if random.randint(2):
   208                                                       delta = random.uniform(-self.delta, self.delta)
   209                                                       image += delta
   210                                                   return image, boxes, labels

Total time: 0 s
File: /mnt/sdc1/yanleizhang/workspace/pytorch_projects/ssd.pytorch/utils/augmentations.py
Function: __call__ at line 214

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   214                                               @profile
   215                                               def __call__(self, tensor, boxes=None, labels=None):
   216                                                   return tensor.cpu().numpy().astype(np.float32).transpose((1, 2, 0)), boxes, labels

Total time: 0 s
File: /mnt/sdc1/yanleizhang/workspace/pytorch_projects/ssd.pytorch/utils/augmentations.py
Function: __call__ at line 220

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   220                                               @profile
   221                                               def __call__(self, cvimage, boxes=None, labels=None):
   222                                                   return torch.from_numpy(cvimage.astype(np.float32)).permute(2, 0, 1), boxes, labels

Total time: 0 s
File: /mnt/sdc1/yanleizhang/workspace/pytorch_projects/ssd.pytorch/utils/augmentations.py
Function: __call__ at line 252

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   252                                               @profile
   253                                               def __call__(self, image, boxes=None, labels=None):
   254                                                   height, width, _ = image.shape
   255                                                   while True:
   256                                                       # randomly choose a mode
   257                                                       mode = random.choice(self.sample_options)
   258                                                       if mode is None:
   259                                                           return image, boxes, labels
   260                                           
   261                                                       min_iou, max_iou = mode
   262                                                       if min_iou is None:
   263                                                           min_iou = float('-inf')
   264                                                       if max_iou is None:
   265                                                           max_iou = float('inf')
   266                                           
   267                                                       # max trails (50)
   268                                                       for _ in range(50):
   269                                                           current_image = image
   270                                           
   271                                                           w = random.uniform(0.3 * width, width)
   272                                                           h = random.uniform(0.3 * height, height)
   273                                           
   274                                                           # aspect ratio constraint b/t .5 & 2
   275                                                           if h / w < 0.5 or h / w > 2:
   276                                                               continue
   277                                           
   278                                                           left = random.uniform(width - w)
   279                                                           top = random.uniform(height - h)
   280                                           
   281                                                           # convert to integer rect x1,y1,x2,y2
   282                                                           rect = np.array(
   283                                                               [int(left), int(top), int(left + w), int(top + h)])
   284                                           
   285                                                           # calculate IoU (jaccard overlap) b/t the cropped and gt boxes
   286                                                           overlap = jaccard_numpy(boxes, rect)
   287                                           
   288                                                           # is min and max overlap constraint satisfied? if not try again
   289                                                           if overlap.min() < min_iou and max_iou < overlap.max():
   290                                                               continue
   291                                           
   292                                                           # cut the crop from the image
   293                                                           current_image = current_image[rect[1]:rect[3], rect[0]:rect[2],
   294                                                                                         :]
   295                                           
   296                                                           # keep overlap with gt box IF center in sampled patch
   297                                                           centers = (boxes[:, :2] + boxes[:, 2:]) / 2.0
   298                                           
   299                                                           # mask in all gt boxes that above and to the left of centers
   300                                                           m1 = (rect[0] < centers[:, 0]) * (rect[1] < centers[:, 1])
   301                                           
   302                                                           # mask in all gt boxes that under and to the right of centers
   303                                                           m2 = (rect[2] > centers[:, 0]) * (rect[3] > centers[:, 1])
   304                                           
   305                                                           # mask in that both m1 and m2 are true
   306                                                           mask = m1 * m2
   307                                           
   308                                                           # have any valid boxes? try again if not
   309                                                           if not mask.any():
   310                                                               continue
   311                                           
   312                                                           # take only matching gt boxes
   313                                                           current_boxes = boxes[mask, :].copy()
   314                                           
   315                                                           # take only matching gt labels
   316                                                           current_labels = labels[mask]
   317                                           
   318                                                           # should we use the box left and top corner or the crop's
   319                                                           current_boxes[:, :2] = np.maximum(current_boxes[:, :2],
   320                                                                                             rect[:2])
   321                                                           # adjust to crop (by substracting crop's left,top)
   322                                                           current_boxes[:, :2] -= rect[:2]
   323                                           
   324                                                           current_boxes[:, 2:] = np.minimum(current_boxes[:, 2:],
   325                                                                                             rect[2:])
   326                                                           # adjust to crop (by substracting crop's left,top)
   327                                                           current_boxes[:, 2:] -= rect[:2]
   328                                           
   329                                                           return current_image, current_boxes, current_labels

Total time: 0 s
File: /mnt/sdc1/yanleizhang/workspace/pytorch_projects/ssd.pytorch/utils/augmentations.py
Function: __call__ at line 336

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   336                                               @profile
   337                                               def __call__(self, image, boxes, labels):
   338                                                   if random.randint(2):
   339                                                       return image, boxes, labels
   340                                           
   341                                                   height, width, depth = image.shape
   342                                                   ratio = random.uniform(1, 4)
   343                                                   left = random.uniform(0, width * ratio - width)
   344                                                   top = random.uniform(0, height * ratio - height)
   345                                           
   346                                                   expand_image = np.zeros(
   347                                                       (int(height * ratio), int(width * ratio), depth),
   348                                                       dtype=image.dtype)
   349                                                   expand_image[:, :, :] = self.mean
   350                                                   expand_image[int(top):int(top + height),
   351                                                                int(left):int(left + width)] = image
   352                                                   image = expand_image
   353                                           
   354                                                   boxes = boxes.copy()
   355                                                   boxes[:, :2] += (int(left), int(top))
   356                                                   boxes[:, 2:] += (int(left), int(top))
   357                                           
   358                                                   return image, boxes, labels

Total time: 0 s
File: /mnt/sdc1/yanleizhang/workspace/pytorch_projects/ssd.pytorch/utils/augmentations.py
Function: __call__ at line 362

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   362                                               @profile
   363                                               def __call__(self, image, boxes, classes):
   364                                                   _, width, _ = image.shape
   365                                                   if random.randint(2):
   366                                                       image = image[:, ::-1]
   367                                                       boxes = boxes.copy()
   368                                                       boxes[:, 0::2] = width - boxes[:, 2::-2]
   369                                                   return image, boxes, classes

Total time: 0 s
File: /mnt/sdc1/yanleizhang/workspace/pytorch_projects/ssd.pytorch/utils/augmentations.py
Function: __call__ at line 383

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   383                                               @profile
   384                                               def __call__(self, image):
   385                                                   """
   386                                                   Args:
   387                                                       image (Tensor): image tensor to be transformed
   388                                                   Return:
   389                                                       a tensor with channels swapped according to swap
   390                                                   """
   391                                                   # if torch.is_tensor(image):
   392                                                   #     image = image.data.cpu().numpy()
   393                                                   # else:
   394                                                   #     image = np.array(image)
   395                                                   image = image[:, :, self.swaps]
   396                                                   return image

Total time: 0 s
File: /mnt/sdc1/yanleizhang/workspace/pytorch_projects/ssd.pytorch/utils/augmentations.py
Function: __call__ at line 412

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   412                                               @profile
   413                                               def __call__(self, image, boxes, labels):
   414                                                   im = image.copy()
   415                                                   im, boxes, labels = self.rand_brightness(im, boxes, labels)
   416                                                   if random.randint(2):
   417                                                       distort = Compose(self.pd[:-1])
   418                                                   else:
   419                                                       distort = Compose(self.pd[1:])
   420                                                   im, boxes, labels = distort(im, boxes, labels)
   421                                                   return self.rand_light_noise(im, boxes, labels)

Total time: 0.000118 s
File: /mnt/sdc1/yanleizhang/workspace/pytorch_projects/ssd.pytorch/utils/augmentations.py
Function: __init__ at line 425

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   425                                               @profile
   426                                               def __init__(self, size=300, mean=(104, 117, 123)):
   427         1          2.0      2.0      1.7          self.mean = mean
   428         1          2.0      2.0      1.7          self.size = size
   429         1          2.0      2.0      1.7          self.augment = Compose([
   430         1          1.0      1.0      0.8              ConvertFromInts(),
   431         1          1.0      1.0      0.8              ToAbsoluteCoords(),
   432         1         55.0     55.0     46.6              PhotometricDistort(),
   433         1          6.0      6.0      5.1              Expand(self.mean),
   434         1          7.0      7.0      5.9              RandomSampleCrop(),
   435         1          1.0      1.0      0.8              RandomMirror(),
   436         1          1.0      1.0      0.8              ToPercentCoords(),
   437         1          4.0      4.0      3.4              Resize(self.size),
   438         1         36.0     36.0     30.5              SubtractMeans(self.mean)
   439                                                   ])

Total time: 0 s
File: /mnt/sdc1/yanleizhang/workspace/pytorch_projects/ssd.pytorch/utils/augmentations.py
Function: __call__ at line 441

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   441                                               @profile
   442                                               def __call__(self, img, boxes, labels):
   443                                                   return self.augment(img, boxes, labels)

Total time: 1324.08 s
File: train.py
Function: train at line 71

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    71                                           @profile
    72                                           def train():
    73         1          8.0      8.0      0.0      if args.dataset == 'COCO':
    74                                                   if args.dataset_root == VOC_ROOT:
    75                                                       if not os.path.exists(COCO_ROOT):
    76                                                           parser.error('Must specify dataset_root if specifying dataset')
    77                                                       print("WARNING: Using default COCO dataset_root because " +
    78                                                             "--dataset_root was not specified.")
    79                                                       args.dataset_root = COCO_ROOT
    80                                                   cfg = coco
    81                                                   dataset = COCODetection(root=args.dataset_root,
    82                                                                           transform=SSDAugmentation(cfg['min_dim'],
    83                                                                                                     MEANS))
    84         1          5.0      5.0      0.0      elif args.dataset == 'VOC':
    85         1          5.0      5.0      0.0          if args.dataset_root == COCO_ROOT:
    86                                                       parser.error('Must specify dataset if specifying dataset_root')
    87         1          5.0      5.0      0.0          cfg = voc
    88         1          6.0      6.0      0.0          dataset = VOCDetection(root=args.dataset_root,
    89         1          6.0      6.0      0.0                                 transform=SSDAugmentation(cfg['min_dim'],
    90         1      28967.0  28967.0      0.0                                                           MEANS))
    91                                           
    92         1          6.0      6.0      0.0      if args.visdom:
    93                                                   import visdom
    94                                                   viz = visdom.Visdom()
    95                                           
    96         1    8827565.0 8827565.0      0.7      ssd_net = build_ssd('train', cfg['min_dim'], cfg['num_classes'])
    97         1          3.0      3.0      0.0      net = ssd_net
    98                                           
    99         1          5.0      5.0      0.0      if args.cuda:
   100         1        147.0    147.0      0.0          net = torch.nn.DataParallel(ssd_net)
   101         1          8.0      8.0      0.0          cudnn.benchmark = False
   102                                           
   103         1         11.0     11.0      0.0      if args.resume:
   104                                                   print('Resuming training, loading {}...'.format(args.resume))
   105                                                   ssd_net.load_weights(args.resume)
   106                                               else:
   107         1     751231.0 751231.0      0.1          vgg_weights = torch.load(args.save_folder + args.basenet)
   108         1         74.0     74.0      0.0          print('Loading base network...')
   109         1     121581.0 121581.0      0.0          ssd_net.vgg.load_state_dict(vgg_weights)
   110                                           
   111         1          6.0      6.0      0.0      if args.cuda:
   112         1       1085.0   1085.0      0.0          net = net.cuda()
   113                                           
   114         1          3.0      3.0      0.0      if not args.resume:
   115         1         40.0     40.0      0.0          print('Initializing weights...')
   116                                                   # initialize newly added layers' weights with xavier method
   117         1        487.0    487.0      0.0          ssd_net.extras.apply(weights_init)
   118         1        222.0    222.0      0.0          ssd_net.loc.apply(weights_init)
   119         1        218.0    218.0      0.0          ssd_net.conf.apply(weights_init)
   120                                           
   121         1          9.0      9.0      0.0      optimizer = optim.SGD(net.parameters(), lr=args.lr, momentum=args.momentum,
   122         1        954.0    954.0      0.0                            weight_decay=args.weight_decay)
   123         1          5.0      5.0      0.0      criterion = MultiBoxLoss(cfg['num_classes'], 0.5, True, 0, True, 3, 0.5,
   124         1        150.0    150.0      0.0                               False, args.cuda)
   125                                           
   126         1        689.0    689.0      0.0      net.train()
   127                                               # loss counters
   128         1          3.0      3.0      0.0      loc_loss = 0
   129         1          3.0      3.0      0.0      conf_loss = 0
   130         1          2.0      2.0      0.0      epoch = 0
   131         1         18.0     18.0      0.0      print('Loading the dataset...')
   132                                           
   133         1         20.0     20.0      0.0      epoch_size = len(dataset) // args.batch_size
   134         1         10.0     10.0      0.0      print('Training SSD on:', dataset.name)
   135         1          7.0      7.0      0.0      print('Using the specified args:')
   136         1        107.0    107.0      0.0      print(args)
   137                                           
   138         1          2.0      2.0      0.0      step_index = 0
   139                                           
   140         1          3.0      3.0      0.0      if args.visdom:
   141                                                   vis_title = 'SSD.PyTorch on ' + dataset.name
   142                                                   vis_legend = ['Loc Loss', 'Conf Loss', 'Total Loss']
   143                                                   iter_plot = create_vis_plot('Iteration', 'Loss', vis_title, vis_legend)
   144                                                   epoch_plot = create_vis_plot('Epoch', 'Loss', vis_title, vis_legend)
   145                                           
   146         1          6.0      6.0      0.0      data_loader = data.DataLoader(dataset, args.batch_size,
   147         1          3.0      3.0      0.0                                    num_workers=args.num_workers,
   148         1          3.0      3.0      0.0                                    shuffle=True, collate_fn=detection_collate,
   149         1         51.0     51.0      0.0                                    pin_memory=True)
   150                                               # create batch iterator
   151         1     126868.0 126868.0      0.0      batch_iterator = iter(data_loader)
   152      1001       4047.0      4.0      0.0      for iteration in range(args.start_iter, cfg['max_iter']):
   153      1000       5405.0      5.4      0.0          if args.visdom and iteration != 0 and (iteration % epoch_size == 0):
   154                                                       update_vis_plot(epoch, loc_loss, conf_loss, epoch_plot, None,
   155                                                                       'append', epoch_size)
   156                                                       # reset epoch loss counters
   157                                                       loc_loss = 0
   158                                                       conf_loss = 0
   159                                                       epoch += 1
   160                                           
   161      1000       5817.0      5.8      0.0          if iteration in cfg['lr_steps']:
   162                                                       step_index += 1
   163                                                       adjust_learning_rate(optimizer, args.gamma, step_index)
   164                                           
   165                                                   # load train data
   166                                                   # images, targets = next(batch_iterator)
   167                                           
   168      1000       3421.0      3.4      0.0          try:
   169      1000   62702801.0  62702.8      4.7              images, targets = next(batch_iterator)
   170         1          7.0      7.0      0.0          except StopIteration:
   171         1    1819784.0 1819784.0      0.1              batch_iterator = iter(data_loader)
   172         1    5645826.0 5645826.0      0.4              images, targets = next(batch_iterator)
   173                                           
   174      1000       5257.0      5.3      0.0          if args.cuda:
   175      1000    5774645.0   5774.6      0.4              images = Variable(images.cuda())
   176      1000    2956200.0   2956.2      0.2              targets = [Variable(ann.cuda(), volatile=True) for ann in targets]
   177                                                   else:
   178                                                       images = Variable(images)
   179                                                       targets = [Variable(ann, volatile=True) for ann in targets]
   180                                                   # forward
   181      1000       7800.0      7.8      0.0          t0 = time.time()
   182      1000  254067080.0 254067.1     19.2          out = net(images)
   183                                                   # backprop
   184      1000     960727.0    960.7      0.1          optimizer.zero_grad()
   185      1000  537850618.0 537850.6     40.6          loss_l, loss_c = criterion(out, targets)
   186      1000    1583795.0   1583.8      0.1          loss = loss_l + loss_c
   187      1000   53512306.0  53512.3      4.0          loss.backward()
   188      1000    4358701.0   4358.7      0.3          optimizer.step()
   189      1000       8735.0      8.7      0.0          t1 = time.time()
   190      1000  382309637.0 382309.6     28.9          loc_loss += loss_l.data[0]
   191      1000     106198.0    106.2      0.0          conf_loss += loss_c.data[0]
   192                                           
   193      1000       6072.0      6.1      0.0          if iteration % 10 == 0:
   194       100     109589.0   1095.9      0.0              print('timer: %.4f sec.' % (t1 - t0))
   195       100        658.0      6.6      0.0              print('iter ' + repr(iteration) + ' || Loss: %.4f ||' %
   196       100       5303.0     53.0      0.0                    (loss.data[0]), end=' ')
   197                                           
   198      1000       6315.0      6.3      0.0          if args.visdom:
   199                                                       update_vis_plot(iteration, loss_l.data[0], loss_c.data[0],
   200                                                                       iter_plot, epoch_plot, 'append')
   201                                           
   202      1000       8904.0      8.9      0.0          if iteration != 0 and iteration % 5000 == 0:
   203                                                       print('Saving state, iter:', iteration)
   204                                                       torch.save(ssd_net.state_dict(), 'weights/ssd300_COCO_' +
   205                                                                  repr(iteration) + '.pth')
   206         1       1211.0   1211.0      0.0      torch.save(ssd_net.state_dict(),
   207         1     397068.0 397068.0      0.0                 args.save_folder + '' + args.dataset + '.pth')

Total time: 0 s
File: train.py
Function: adjust_learning_rate at line 210

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   210                                           @profile
   211                                           def adjust_learning_rate(optimizer, gamma, step):
   212                                               """Sets the learning rate to the initial LR decayed by 10 at every
   213                                                   specified step
   214                                               # Adapted from PyTorch Imagenet example:
   215                                               # https://github.com/pytorch/examples/blob/master/imagenet/main.py
   216                                               """
   217                                               lr = args.lr * (gamma ** (step))
   218                                               for param_group in optimizer.param_groups:
   219                                                   param_group['lr'] = lr

