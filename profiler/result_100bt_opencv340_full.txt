Timer unit: 1e-06 s

Total time: 0.456717 s
File: /mnt/sdc1/yanleizhang/workspace/pytorch_projects/ssd.pytorch/layers/box_utils.py
Function: point_form at line 5

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
     5                                           @profile
     6                                           def point_form(boxes):
     7                                               """ Convert prior_boxes to (xmin, ymin, xmax, ymax)
     8                                               representation for comparison to point form ground truth data.
     9                                               Args:
    10                                                   boxes: (tensor) center-size default boxes from priorbox layers.
    11                                               Return:
    12                                                   boxes: (tensor) Converted xmin, ymin, xmax, ymax form of boxes.
    13                                               """
    14      3200     181874.0     56.8     39.8      return torch.cat((boxes[:, :2] - boxes[:, 2:] / 2,     # xmin, ymin
    15      3200     274843.0     85.9     60.2                        boxes[:, :2] + boxes[:, 2:] / 2), 1)  # xmax, ymax

Total time: 0 s
File: /mnt/sdc1/yanleizhang/workspace/pytorch_projects/ssd.pytorch/layers/box_utils.py
Function: center_size at line 18

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    18                                           @profile
    19                                           def center_size(boxes):
    20                                               """ Convert prior_boxes to (cx, cy, w, h)
    21                                               representation for comparison to center-size form ground truth data.
    22                                               Args:
    23                                                   boxes: (tensor) point_form boxes
    24                                               Return:
    25                                                   boxes: (tensor) Converted xmin, ymin, xmax, ymax form of boxes.
    26                                               """
    27                                               return torch.cat((boxes[:, 2:] + boxes[:, :2]) / 2,  # cx, cy
    28                                                                boxes[:, 2:] - boxes[:, :2], 1)  # w, h

Total time: 0.480266 s
File: /mnt/sdc1/yanleizhang/workspace/pytorch_projects/ssd.pytorch/layers/box_utils.py
Function: intersect at line 31

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    31                                           @profile
    32                                           def intersect(box_a, box_b):
    33                                               """ We resize both tensors to [A,B,2] without new malloc:
    34                                               [A,2] -> [A,1,2] -> [A,B,2]
    35                                               [B,2] -> [1,B,2] -> [A,B,2]
    36                                               Then we compute the area of intersect between box_a and box_b.
    37                                               Args:
    38                                                 box_a: (tensor) bounding boxes, Shape: [A,4].
    39                                                 box_b: (tensor) bounding boxes, Shape: [B,4].
    40                                               Return:
    41                                                 (tensor) intersection area, Shape: [A,B].
    42                                               """
    43      3200       5100.0      1.6      1.1      A = box_a.size(0)
    44      3200       3078.0      1.0      0.6      B = box_b.size(0)
    45      3200      46189.0     14.4      9.6      max_xy = torch.min(box_a[:, 2:].unsqueeze(1).expand(A, B, 2),
    46      3200      96879.0     30.3     20.2                         box_b[:, 2:].unsqueeze(0).expand(A, B, 2))
    47      3200      25535.0      8.0      5.3      min_xy = torch.max(box_a[:, :2].unsqueeze(1).expand(A, B, 2),
    48      3200      87268.0     27.3     18.2                         box_b[:, :2].unsqueeze(0).expand(A, B, 2))
    49      3200     133099.0     41.6     27.7      inter = torch.clamp((max_xy - min_xy), min=0)
    50      3200      83118.0     26.0     17.3      return inter[:, :, 0] * inter[:, :, 1]

Total time: 1.08678 s
File: /mnt/sdc1/yanleizhang/workspace/pytorch_projects/ssd.pytorch/layers/box_utils.py
Function: jaccard at line 53

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    53                                           @profile
    54                                           def jaccard(box_a, box_b):
    55                                               """Compute the jaccard overlap of two sets of boxes.  The jaccard overlap
    56                                               is simply the intersection over union of two boxes.  Here we operate on
    57                                               ground truth boxes and default boxes.
    58                                               E.g.:
    59                                                   A ∩ B / A ∪ B = A ∩ B / (area(A) + area(B) - A ∩ B)
    60                                               Args:
    61                                                   box_a: (tensor) Ground truth bounding boxes, Shape: [num_objects,4]
    62                                                   box_b: (tensor) Prior boxes from priorbox layers, Shape: [num_priors,4]
    63                                               Return:
    64                                                   jaccard overlap: (tensor) Shape: [box_a.size(0), box_b.size(0)]
    65                                               """
    66      3200     532438.0    166.4     49.0      inter = intersect(box_a, box_b)
    67      3200      70172.0     21.9      6.5      area_a = ((box_a[:, 2] - box_a[:, 0]) *
    68      3200     133233.0     41.6     12.3                (box_a[:, 3] - box_a[:, 1])).unsqueeze(1).expand_as(inter)  # [A,B]
    69      3200      63897.0     20.0      5.9      area_b = ((box_b[:, 2] - box_b[:, 0]) *
    70      3200     122414.0     38.3     11.3                (box_b[:, 3] - box_b[:, 1])).unsqueeze(0).expand_as(inter)  # [A,B]
    71      3200     106786.0     33.4      9.8      union = area_a + area_b - inter
    72      3200      57839.0     18.1      5.3      return inter / union  # [A,B]

Total time: 62.6187 s
File: /mnt/sdc1/yanleizhang/workspace/pytorch_projects/ssd.pytorch/layers/box_utils.py
Function: match at line 75

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    75                                           @profile
    76                                           def match(threshold, truths, priors, variances, labels, loc_t, conf_t, idx):
    77                                               """Match each prior box with the ground truth box of the highest jaccard
    78                                               overlap, encode the bounding boxes, then return the matched indices
    79                                               corresponding to both confidence and location preds.
    80                                               Args:
    81                                                   threshold: (float) The overlap threshold used when mathing boxes.
    82                                                   truths: (tensor) Ground truth boxes, Shape: [num_obj, num_priors].
    83                                                   priors: (tensor) Prior boxes from priorbox layers, Shape: [n_priors,4].
    84                                                   variances: (tensor) Variances corresponding to each prior coord,
    85                                                       Shape: [num_priors, 4].
    86                                                   labels: (tensor) All the class labels for the image, Shape: [num_obj].
    87                                                   loc_t: (tensor) Tensor to be filled w/ endcoded location targets.
    88                                                   conf_t: (tensor) Tensor to be filled w/ matched indices for conf preds.
    89                                                   idx: (int) current batch index
    90                                               Return:
    91                                                   The matched indices corresponding to 1)location and 2)confidence preds.
    92                                               """
    93                                               # jaccard index
    94      3200       3626.0      1.1      0.0      overlaps = jaccard(
    95      3200       2395.0      0.7      0.0          truths,
    96      3200    1622500.0    507.0      2.6          point_form(priors)
    97                                               )
    98                                               # (Bipartite Matching)
    99                                               # [1,num_objects] best prior for each ground truth
   100      3200      85087.0     26.6      0.1      best_prior_overlap, best_prior_idx = overlaps.max(1, keepdim=True)
   101                                               # [1,num_priors] best ground truth for each prior
   102      3200      58508.0     18.3      0.1      best_truth_overlap, best_truth_idx = overlaps.max(0, keepdim=True)
   103      3200      11246.0      3.5      0.0      best_truth_idx.squeeze_(0)
   104      3200       6749.0      2.1      0.0      best_truth_overlap.squeeze_(0)
   105      3200       5237.0      1.6      0.0      best_prior_idx.squeeze_(1)
   106      3200       5167.0      1.6      0.0      best_prior_overlap.squeeze_(1)
   107      3200      60249.0     18.8      0.1      best_truth_overlap.index_fill_(0, best_prior_idx, 2)  # ensure best prior
   108                                               # TODO refactor: index  best_prior_idx with long tensor
   109                                               # ensure every gt matches with its prior of max overlap
   110      9640      27626.0      2.9      0.0      for j in range(best_prior_idx.size(0)):
   111      6440   49533919.0   7691.6     79.1          best_truth_idx[best_prior_idx[j]] = j
   112      3200      91589.0     28.6      0.1      matches = truths[best_truth_idx]          # Shape: [num_priors,4]
   113      3200     133997.0     41.9      0.2      conf = labels[best_truth_idx] + 1         # Shape: [num_priors]
   114      3200     132536.0     41.4      0.2      conf[best_truth_overlap < threshold] = 0  # label as background
   115      3200     841805.0    263.1      1.3      loc = encode(matches, priors, variances)
   116      3200      76308.0     23.8      0.1      loc_t[idx] = loc    # [num_priors,4] encoded offsets to learn
   117      3200    9920156.0   3100.0     15.8      conf_t[idx] = conf  # [num_priors] top class label for each prior

Total time: 0.786366 s
File: /mnt/sdc1/yanleizhang/workspace/pytorch_projects/ssd.pytorch/layers/box_utils.py
Function: encode at line 120

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   120                                           @profile
   121                                           def encode(matched, priors, variances):
   122                                               """Encode the variances from the priorbox layers into the ground truth boxes
   123                                               we have matched (based on jaccard overlap) with the prior boxes.
   124                                               Args:
   125                                                   matched: (tensor) Coords of ground truth for each prior in point-form
   126                                                       Shape: [num_priors, 4].
   127                                                   priors: (tensor) Prior boxes in center-offset form
   128                                                       Shape: [num_priors,4].
   129                                                   variances: (list[float]) Variances of priorboxes
   130                                               Return:
   131                                                   encoded boxes (tensor), Shape: [num_priors, 4]
   132                                               """
   133                                           
   134                                               # dist b/t match center and prior's center
   135      3200     225367.0     70.4     28.7      g_cxcy = (matched[:, :2] + matched[:, 2:]) / 2 - priors[:, :2]
   136                                               # encode variance
   137      3200     123580.0     38.6     15.7      g_cxcy /= (variances[0] * priors[:, 2:])
   138                                               # match wh / prior wh
   139      3200     135304.0     42.3     17.2      g_wh = (matched[:, 2:] - matched[:, :2]) / priors[:, 2:]
   140      3200     130716.0     40.8     16.6      g_wh = torch.log(g_wh) / variances[1]
   141                                               # return target for smooth_l1_loss
   142      3200     171399.0     53.6     21.8      return torch.cat([g_cxcy, g_wh], 1)  # [num_priors,4]

Total time: 0 s
File: /mnt/sdc1/yanleizhang/workspace/pytorch_projects/ssd.pytorch/layers/box_utils.py
Function: decode at line 146

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   146                                           @profile
   147                                           def decode(loc, priors, variances):
   148                                               """Decode locations from predictions using priors to undo
   149                                               the encoding we did for offset regression at train time.
   150                                               Args:
   151                                                   loc (tensor): location predictions for loc layers,
   152                                                       Shape: [num_priors,4]
   153                                                   priors (tensor): Prior boxes in center-offset form.
   154                                                       Shape: [num_priors,4].
   155                                                   variances: (list[float]) Variances of priorboxes
   156                                               Return:
   157                                                   decoded bounding box predictions
   158                                               """
   159                                           
   160                                               boxes = torch.cat((
   161                                                   priors[:, :2] + loc[:, :2] * variances[0] * priors[:, 2:],
   162                                                   priors[:, 2:] * torch.exp(loc[:, 2:] * variances[1])), 1)
   163                                               boxes[:, :2] -= boxes[:, 2:] / 2
   164                                               boxes[:, 2:] += boxes[:, :2]
   165                                               return boxes

Total time: 0.362126 s
File: /mnt/sdc1/yanleizhang/workspace/pytorch_projects/ssd.pytorch/layers/box_utils.py
Function: log_sum_exp at line 168

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   168                                           @profile
   169                                           def log_sum_exp(x):
   170                                               """Utility function for computing log_sum_exp while determining
   171                                               This will be used to determine unaveraged confidence loss across
   172                                               all examples in a batch.
   173                                               Args:
   174                                                   x (Variable(tensor)): conf_preds from conf layers
   175                                               """
   176       100     227672.0   2276.7     62.9      x_max = x.data.max()
   177       100     134454.0   1344.5     37.1      return torch.log(torch.sum(torch.exp(x - x_max), 1, keepdim=True)) + x_max

Total time: 0 s
File: /mnt/sdc1/yanleizhang/workspace/pytorch_projects/ssd.pytorch/layers/box_utils.py
Function: nms at line 183

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   183                                           @profile
   184                                           def nms(boxes, scores, overlap=0.5, top_k=200):
   185                                               """Apply non-maximum suppression at test time to avoid detecting too many
   186                                               overlapping bounding boxes for a given object.
   187                                               Args:
   188                                                   boxes: (tensor) The location preds for the img, Shape: [num_priors,4].
   189                                                   scores: (tensor) The class predscores for the img, Shape:[num_priors].
   190                                                   overlap: (float) The overlap thresh for suppressing unnecessary boxes.
   191                                                   top_k: (int) The Maximum number of box preds to consider.
   192                                               Return:
   193                                                   The indices of the kept boxes with respect to num_priors.
   194                                               """
   195                                           
   196                                               keep = scores.new(scores.size(0)).zero_().long()
   197                                               if boxes.numel() == 0:
   198                                                   return keep
   199                                               x1 = boxes[:, 0]
   200                                               y1 = boxes[:, 1]
   201                                               x2 = boxes[:, 2]
   202                                               y2 = boxes[:, 3]
   203                                               area = torch.mul(x2 - x1, y2 - y1)
   204                                               v, idx = scores.sort(0)  # sort in ascending order
   205                                               # I = I[v >= 0.01]
   206                                               idx = idx[-top_k:]  # indices of the top-k largest vals
   207                                               xx1 = boxes.new()
   208                                               yy1 = boxes.new()
   209                                               xx2 = boxes.new()
   210                                               yy2 = boxes.new()
   211                                               w = boxes.new()
   212                                               h = boxes.new()
   213                                           
   214                                               # keep = torch.Tensor()
   215                                               count = 0
   216                                               while idx.numel() > 0:
   217                                                   i = idx[-1]  # index of current largest val
   218                                                   # keep.append(i)
   219                                                   keep[count] = i
   220                                                   count += 1
   221                                                   if idx.size(0) == 1:
   222                                                       break
   223                                                   idx = idx[:-1]  # remove kept element from view
   224                                                   # load bboxes of next highest vals
   225                                                   torch.index_select(x1, 0, idx, out=xx1)
   226                                                   torch.index_select(y1, 0, idx, out=yy1)
   227                                                   torch.index_select(x2, 0, idx, out=xx2)
   228                                                   torch.index_select(y2, 0, idx, out=yy2)
   229                                                   # store element-wise max with next highest score
   230                                                   xx1 = torch.clamp(xx1, min=x1[i])
   231                                                   yy1 = torch.clamp(yy1, min=y1[i])
   232                                                   xx2 = torch.clamp(xx2, max=x2[i])
   233                                                   yy2 = torch.clamp(yy2, max=y2[i])
   234                                                   w.resize_as_(xx2)
   235                                                   h.resize_as_(yy2)
   236                                                   w = xx2 - xx1
   237                                                   h = yy2 - yy1
   238                                                   # check sizes of xx1 and xx2.. after each iteration
   239                                                   w = torch.clamp(w, min=0.0)
   240                                                   h = torch.clamp(h, min=0.0)
   241                                                   inter = w * h
   242                                                   # IoU = i / (area(a) + area(b) - i)
   243                                                   rem_areas = torch.index_select(area, 0, idx)  # load remaining areas)
   244                                                   union = (rem_areas - inter) + area[i]
   245                                                   IoU = inter / union  # store result in iou
   246                                                   # keep only elements with an IoU <= overlap
   247                                                   idx = idx[IoU.le(overlap)]
   248                                               return keep, count

Total time: 66.0872 s
File: /mnt/sdc1/yanleizhang/workspace/pytorch_projects/ssd.pytorch/layers/modules/multibox_loss.py
Function: forward at line 48

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    48                                               @profile
    49                                               def forward(self, predictions, targets):
    50                                                   """Multibox Loss
    51                                                   Args:
    52                                                       predictions (tuple): A tuple containing loc preds, conf preds,
    53                                                       and prior boxes from SSD net.
    54                                                           conf shape: torch.size(batch_size,num_priors,num_classes)
    55                                                           loc shape: torch.size(batch_size,num_priors,4)
    56                                                           priors shape: torch.size(num_priors,4)
    57                                           
    58                                                       targets (tensor): Ground truth boxes and labels for a batch,
    59                                                           shape: [batch_size,num_objs,5] (last idx is the label).
    60                                                   """
    61       100        257.0      2.6      0.0          loc_data, conf_data, priors = predictions
    62       100       1211.0     12.1      0.0          num = loc_data.size(0)
    63       100       6310.0     63.1      0.0          priors = priors[:loc_data.size(1), :]
    64       100        592.0      5.9      0.0          num_priors = (priors.size(0))
    65       100        253.0      2.5      0.0          num_classes = self.num_classes
    66                                           
    67                                                   # match priors (default boxes) and ground truth boxes
    68       100       5294.0     52.9      0.0          loc_t = torch.Tensor(num, num_priors, 4)
    69       100      11164.0    111.6      0.0          conf_t = torch.LongTensor(num, num_priors)
    70      3300       8106.0      2.5      0.0          for idx in range(num):
    71      3200     171085.0     53.5      0.3              truths = targets[idx][:, :-1].data
    72      3200      63179.0     19.7      0.1              labels = targets[idx][:, -1].data
    73      3200       5864.0      1.8      0.0              defaults = priors.data
    74      3200       8637.0      2.7      0.0              match(self.threshold, truths, defaults, self.variance, labels,
    75      3200   62756845.0  19611.5     95.0                    loc_t, conf_t, idx)
    76       100        365.0      3.6      0.0          if self.use_gpu:
    77       100       3158.0     31.6      0.0              loc_t = loc_t.cuda()
    78       100      68965.0    689.6      0.1              conf_t = conf_t.cuda()
    79                                                   # wrap targets
    80       100       1301.0     13.0      0.0          loc_t = Variable(loc_t, requires_grad=False)
    81       100        721.0      7.2      0.0          conf_t = Variable(conf_t, requires_grad=False)
    82                                           
    83       100       6111.0     61.1      0.0          pos = conf_t > 0
    84       100       4158.0     41.6      0.0          num_pos = pos.sum(dim=1, keepdim=True)
    85                                           
    86                                                   # Localization Loss (Smooth L1)
    87                                                   # Shape: [batch,num_priors,4]
    88       100       5128.0     51.3      0.0          pos_idx = pos.unsqueeze(pos.dim()).expand_as(loc_data)
    89       100     194766.0   1947.7      0.3          loc_p = loc_data[pos_idx].view(-1, 4)
    90       100     241570.0   2415.7      0.4          loc_t = loc_t[pos_idx].view(-1, 4)
    91       100     669260.0   6692.6      1.0          loss_l = F.smooth_l1_loss(loc_p, loc_t, size_average=False)
    92                                           
    93                                                   # Compute max conf across batch for hard negative mining
    94       100       1714.0     17.1      0.0          batch_conf = conf_data.view(-1, self.num_classes)
    95       100     364270.0   3642.7      0.6          loss_c = log_sum_exp(batch_conf) - \
    96       100       7904.0     79.0      0.0              batch_conf.gather(1, conf_t.view(-1, 1))
    97                                           
    98                                                   # Hard Negative Mining
    99       100      20774.0    207.7      0.0          loss_c[pos] = 0  # filter out pos boxes for now
   100       100       1561.0     15.6      0.0          loss_c = loss_c.view(num, -1)
   101       100      57532.0    575.3      0.1          _, loss_idx = loss_c.sort(1, descending=True)
   102       100      47140.0    471.4      0.1          _, idx_rank = loss_idx.sort(1)
   103       100      18304.0    183.0      0.0          num_pos = pos.long().sum(1, keepdim=True)
   104       100      11843.0    118.4      0.0          num_neg = torch.clamp(self.negpos_ratio * num_pos, max=pos.size(1) - 1)
   105       100       5230.0     52.3      0.0          neg = idx_rank < num_neg.expand_as(idx_rank)
   106                                           
   107                                                   # Confidence Loss Including Positive and Negative Examples
   108       100       2040.0     20.4      0.0          pos_idx = pos.unsqueeze(2).expand_as(conf_data)
   109       100       1111.0     11.1      0.0          neg_idx = neg.unsqueeze(2).expand_as(conf_data)
   110       100     785819.0   7858.2      1.2          conf_p = conf_data[(pos_idx + neg_idx).gt(0)
   111       100       1912.0     19.1      0.0                             ].view(-1, self.num_classes)
   112       100     295358.0   2953.6      0.4          targets_weighted = conf_t[(pos + neg).gt(0)]
   113       100      12028.0    120.3      0.0          loss_c = F.cross_entropy(conf_p, targets_weighted, size_average=False)
   114                                           
   115                                                   # Sum of losses: L(x,c,l,g) = (Lconf(x, c) + αLloc(x,l,g)) / N
   116                                           
   117       100     213230.0   2132.3      0.3          N = num_pos.data.sum()
   118       100       3302.0     33.0      0.0          loss_l /= N
   119       100       1671.0     16.7      0.0          loss_c /= N
   120       100        193.0      1.9      0.0          return loss_l, loss_c

Total time: 0 s
File: /mnt/sdc1/yanleizhang/workspace/pytorch_projects/ssd.pytorch/ssd.py
Function: forward at line 50

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    50                                               @profile
    51                                               def forward(self, x):
    52                                                   """Applies network layers and ops on input image(s) x.
    53                                           
    54                                                   Args:
    55                                                       x: input image or batch of images. Shape: [batch,3,300,300].
    56                                           
    57                                                   Return:
    58                                                       Depending on phase:
    59                                                       test:
    60                                                           Variable(tensor) of output class label predictions,
    61                                                           confidence score, and corresponding location predictions for
    62                                                           each object detected. Shape: [batch,topk,7]
    63                                           
    64                                                       train:
    65                                                           list of concat outputs from:
    66                                                               1: confidence layers, Shape: [batch*num_priors,num_classes]
    67                                                               2: localization layers, Shape: [batch,num_priors*4]
    68                                                               3: priorbox layers, Shape: [2,num_priors*4]
    69                                                   """
    70                                                   sources = list()
    71                                                   loc = list()
    72                                                   conf = list()
    73                                           
    74                                                   # apply vgg up to conv4_3 relu
    75                                                   for k in range(23):
    76                                                       x = self.vgg[k](x)
    77                                           
    78                                                   s = self.L2Norm(x)
    79                                                   sources.append(s)
    80                                           
    81                                                   # apply vgg up to fc7
    82                                                   for k in range(23, len(self.vgg)):
    83                                                       x = self.vgg[k](x)
    84                                                   sources.append(x)
    85                                           
    86                                                   # apply extra layers and cache source layer outputs
    87                                                   for k, v in enumerate(self.extras):
    88                                                       x = F.relu(v(x), inplace=True)
    89                                                       if k % 2 == 1:
    90                                                           sources.append(x)
    91                                           
    92                                                   # apply multibox head to source layers
    93                                                   for (x, l, c) in zip(sources, self.loc, self.conf):
    94                                                       loc.append(l(x).permute(0, 2, 3, 1).contiguous())
    95                                                       conf.append(c(x).permute(0, 2, 3, 1).contiguous())
    96                                           
    97                                                   loc = torch.cat([o.view(o.size(0), -1) for o in loc], 1)
    98                                                   conf = torch.cat([o.view(o.size(0), -1) for o in conf], 1)
    99                                                   if self.phase == "test":
   100                                                       output = self.detect(
   101                                                           loc.view(loc.size(0), -1, 4),                   # loc preds
   102                                                           self.softmax(conf.view(conf.size(0), -1,
   103                                                                                  self.num_classes)),                # conf preds
   104                                                           self.priors.type(type(x.data))                  # default boxes
   105                                                       )
   106                                                   else:
   107                                                       output = (
   108                                                           loc.view(loc.size(0), -1, 4),
   109                                                           conf.view(conf.size(0), -1, self.num_classes),
   110                                                           self.priors
   111                                                       )
   112                                                   return output

Total time: 0 s
File: /mnt/sdc1/yanleizhang/workspace/pytorch_projects/ssd.pytorch/ssd.py
Function: load_weights at line 114

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   114                                               @profile
   115                                               def load_weights(self, base_file):
   116                                                   other, ext = os.path.splitext(base_file)
   117                                                   if ext == '.pkl' or '.pth':
   118                                                       print('Loading weights into state dict...')
   119                                                       self.load_state_dict(torch.load(base_file,
   120                                                                                       map_location=lambda storage, loc: storage))
   121                                                       print('Finished!')
   122                                                   else:
   123                                                       print('Sorry only .pth and .pkl files supported.')

Total time: 12.5034 s
File: /mnt/sdc1/yanleizhang/workspace/pytorch_projects/ssd.pytorch/ssd.py
Function: vgg at line 128

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   128                                           @profile
   129                                           def vgg(cfg, i, batch_norm=False):
   130         1          1.0      1.0      0.0      layers = []
   131         1          1.0      1.0      0.0      in_channels = i
   132        18         24.0      1.3      0.0      for v in cfg:
   133        17         23.0      1.4      0.0          if v == 'M':
   134         3        395.0    131.7      0.0              layers += [nn.MaxPool2d(kernel_size=2, stride=2)]
   135        14         12.0      0.9      0.0          elif v == 'C':
   136         1        103.0    103.0      0.0              layers += [nn.MaxPool2d(kernel_size=2, stride=2, ceil_mode=True)]
   137                                                   else:
   138        13   12488051.0 960619.3     99.9              conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)
   139        13         34.0      2.6      0.0              if batch_norm:
   140                                                           layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]
   141                                                       else:
   142        13       1559.0    119.9      0.0                  layers += [conv2d, nn.ReLU(inplace=True)]
   143        13         12.0      0.9      0.0              in_channels = v
   144         1        188.0    188.0      0.0      pool5 = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)
   145         1       8856.0   8856.0      0.1      conv6 = nn.Conv2d(512, 1024, kernel_size=3, padding=6, dilation=6)
   146         1       3835.0   3835.0      0.0      conv7 = nn.Conv2d(1024, 1024, kernel_size=1)
   147         1          4.0      4.0      0.0      layers += [pool5, conv6,
   148         1        296.0    296.0      0.0                 nn.ReLU(inplace=True), conv7, nn.ReLU(inplace=True)]
   149         1          2.0      2.0      0.0      return layers

Total time: 0.006513 s
File: /mnt/sdc1/yanleizhang/workspace/pytorch_projects/ssd.pytorch/ssd.py
Function: add_extras at line 152

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   152                                           @profile
   153                                           def add_extras(cfg, i, batch_norm=False):
   154                                               # Extra layers added to VGG for feature scaling
   155         1          2.0      2.0      0.0      layers = []
   156         1          1.0      1.0      0.0      in_channels = i
   157         1          1.0      1.0      0.0      flag = False
   158        11         21.0      1.9      0.3      for k, v in enumerate(cfg):
   159        10         14.0      1.4      0.2          if in_channels != 'S':
   160         8          9.0      1.1      0.1              if v == 'S':
   161         2          5.0      2.5      0.1                  layers += [nn.Conv2d(in_channels, cfg[k + 1],
   162         2       3752.0   1876.0     57.6                                       kernel_size=(1, 3)[flag], stride=2, padding=1)]
   163                                                       else:
   164         6       2676.0    446.0     41.1                  layers += [nn.Conv2d(in_channels, v, kernel_size=(1, 3)[flag])]
   165         8         20.0      2.5      0.3              flag = not flag
   166        10         11.0      1.1      0.2          in_channels = v
   167         1          1.0      1.0      0.0      return layers

Total time: 0.005884 s
File: /mnt/sdc1/yanleizhang/workspace/pytorch_projects/ssd.pytorch/ssd.py
Function: multibox at line 170

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   170                                           @profile
   171                                           def multibox(vgg, extra_layers, cfg, num_classes):
   172         1          2.0      2.0      0.0      loc_layers = []
   173         1          1.0      1.0      0.0      conf_layers = []
   174         1          2.0      2.0      0.0      vgg_source = [21, -2]
   175         3         10.0      3.3      0.2      for k, v in enumerate(vgg_source):
   176         2          6.0      3.0      0.1          loc_layers += [nn.Conv2d(vgg[v].out_channels,
   177         2        832.0    416.0     14.1                                   cfg[k] * 4, kernel_size=3, padding=1)]
   178         2          5.0      2.5      0.1          conf_layers += [nn.Conv2d(vgg[v].out_channels,
   179         2       2044.0   1022.0     34.7                                    cfg[k] * num_classes, kernel_size=3, padding=1)]
   180         5         18.0      3.6      0.3      for k, v in enumerate(extra_layers[1::2], 2):
   181         4          7.0      1.8      0.1          loc_layers += [nn.Conv2d(v.out_channels, cfg[k]
   182         4       1044.0    261.0     17.7                                   * 4, kernel_size=3, padding=1)]
   183         4          7.0      1.8      0.1          conf_layers += [nn.Conv2d(v.out_channels, cfg[k]
   184         4       1905.0    476.2     32.4                                    * num_classes, kernel_size=3, padding=1)]
   185         1          1.0      1.0      0.0      return vgg, extra_layers, (loc_layers, conf_layers)

Total time: 12.5344 s
File: /mnt/sdc1/yanleizhang/workspace/pytorch_projects/ssd.pytorch/ssd.py
Function: build_ssd at line 203

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   203                                           @profile
   204                                           def build_ssd(phase, size=300, num_classes=21):
   205         1          1.0      1.0      0.0      if phase != "test" and phase != "train":
   206                                                   print("ERROR: Phase: " + phase + " not recognized")
   207                                                   return
   208         1          1.0      1.0      0.0      if size != 300:
   209                                                   print("ERROR: You specified size " + repr(size) + ". However, " +
   210                                                         "currently only SSD300 (size=300) is supported!")
   211                                                   return
   212         1   12503608.0 12503608.0     99.8      base_, extras_, head_ = multibox(vgg(base[str(size)], 3),
   213         1       6648.0   6648.0      0.1                                       add_extras(extras[str(size)], 1024),
   214         1       5963.0   5963.0      0.0                                       mbox[str(size)], num_classes)
   215         1      18162.0  18162.0      0.1      return SSD(phase, size, base_, extras_, head_, num_classes)

Total time: 0 s
File: /mnt/sdc1/yanleizhang/workspace/pytorch_projects/ssd.pytorch/utils/augmentations.py
Function: intersect at line 9

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
     9                                           @profile
    10                                           def intersect(box_a, box_b):
    11                                               max_xy = np.minimum(box_a[:, 2:], box_b[2:])
    12                                               min_xy = np.maximum(box_a[:, :2], box_b[:2])
    13                                               inter = np.clip((max_xy - min_xy), a_min=0, a_max=np.inf)
    14                                               return inter[:, 0] * inter[:, 1]

Total time: 0 s
File: /mnt/sdc1/yanleizhang/workspace/pytorch_projects/ssd.pytorch/utils/augmentations.py
Function: jaccard_numpy at line 17

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    17                                           @profile
    18                                           def jaccard_numpy(box_a, box_b):
    19                                               """Compute the jaccard overlap of two sets of boxes.  The jaccard overlap
    20                                               is simply the intersection over union of two boxes.
    21                                               E.g.:
    22                                                   A ∩ B / A ∪ B = A ∩ B / (area(A) + area(B) - A ∩ B)
    23                                               Args:
    24                                                   box_a: Multiple bounding boxes, Shape: [num_boxes,4]
    25                                                   box_b: Single bounding box, Shape: [4]
    26                                               Return:
    27                                                   jaccard overlap: Shape: [box_a.shape[0], box_a.shape[1]]
    28                                               """
    29                                               inter = intersect(box_a, box_b)
    30                                               area_a = ((box_a[:, 2] - box_a[:, 0]) *
    31                                                         (box_a[:, 3] - box_a[:, 1]))  # [A,B]
    32                                               area_b = ((box_b[2] - box_b[0]) *
    33                                                         (box_b[3] - box_b[1]))  # [A,B]
    34                                               union = area_a + area_b - inter
    35                                               return inter / union  # [A,B]

Total time: 0 s
File: /mnt/sdc1/yanleizhang/workspace/pytorch_projects/ssd.pytorch/utils/augmentations.py
Function: __call__ at line 52

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    52                                               @profile
    53                                               def __call__(self, img, boxes=None, labels=None):
    54                                                   for t in self.transforms:
    55                                                       img, boxes, labels = t(img, boxes, labels)
    56                                                   return img, boxes, labels

Total time: 0 s
File: /mnt/sdc1/yanleizhang/workspace/pytorch_projects/ssd.pytorch/utils/augmentations.py
Function: __call__ at line 66

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    66                                               @profile
    67                                               def __call__(self, img, boxes=None, labels=None):
    68                                                   return self.lambd(img, boxes, labels)

Total time: 0 s
File: /mnt/sdc1/yanleizhang/workspace/pytorch_projects/ssd.pytorch/utils/augmentations.py
Function: __call__ at line 72

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    72                                               @profile
    73                                               def __call__(self, image, boxes=None, labels=None):
    74                                                   return image.astype(np.float32), boxes, labels

Total time: 0 s
File: /mnt/sdc1/yanleizhang/workspace/pytorch_projects/ssd.pytorch/utils/augmentations.py
Function: __call__ at line 81

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    81                                               @profile
    82                                               def __call__(self, image, boxes=None, labels=None):
    83                                                   image = image.astype(np.float32)
    84                                                   image -= self.mean
    85                                                   return image.astype(np.float32), boxes, labels

Total time: 0 s
File: /mnt/sdc1/yanleizhang/workspace/pytorch_projects/ssd.pytorch/utils/augmentations.py
Function: __call__ at line 89

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    89                                               @profile
    90                                               def __call__(self, image, boxes=None, labels=None):
    91                                                   height, width, channels = image.shape
    92                                                   boxes[:, 0] *= width
    93                                                   boxes[:, 2] *= width
    94                                                   boxes[:, 1] *= height
    95                                                   boxes[:, 3] *= height
    96                                           
    97                                                   return image, boxes, labels

Total time: 0 s
File: /mnt/sdc1/yanleizhang/workspace/pytorch_projects/ssd.pytorch/utils/augmentations.py
Function: __call__ at line 101

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   101                                               @profile
   102                                               def __call__(self, image, boxes=None, labels=None):
   103                                                   height, width, channels = image.shape
   104                                                   boxes[:, 0] /= width
   105                                                   boxes[:, 2] /= width
   106                                                   boxes[:, 1] /= height
   107                                                   boxes[:, 3] /= height
   108                                           
   109                                                   return image, boxes, labels

Total time: 0 s
File: /mnt/sdc1/yanleizhang/workspace/pytorch_projects/ssd.pytorch/utils/augmentations.py
Function: __call__ at line 116

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   116                                               @profile
   117                                               def __call__(self, image, boxes=None, labels=None):
   118                                                   image = cv2.resize(image, (self.size,
   119                                                                              self.size))
   120                                                   return image, boxes, labels

Total time: 0 s
File: /mnt/sdc1/yanleizhang/workspace/pytorch_projects/ssd.pytorch/utils/augmentations.py
Function: __call__ at line 130

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   130                                               @profile
   131                                               def __call__(self, image, boxes=None, labels=None):
   132                                                   if random.randint(2):
   133                                                       image[:, :, 1] *= random.uniform(self.lower, self.upper)
   134                                           
   135                                                   return image, boxes, labels

Total time: 0 s
File: /mnt/sdc1/yanleizhang/workspace/pytorch_projects/ssd.pytorch/utils/augmentations.py
Function: __call__ at line 143

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   143                                               @profile
   144                                               def __call__(self, image, boxes=None, labels=None):
   145                                                   if random.randint(2):
   146                                                       image[:, :, 0] += random.uniform(-self.delta, self.delta)
   147                                                       image[:, :, 0][image[:, :, 0] > 360.0] -= 360.0
   148                                                       image[:, :, 0][image[:, :, 0] < 0.0] += 360.0
   149                                                   return image, boxes, labels

Total time: 0 s
File: /mnt/sdc1/yanleizhang/workspace/pytorch_projects/ssd.pytorch/utils/augmentations.py
Function: __call__ at line 158

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   158                                               @profile
   159                                               def __call__(self, image, boxes=None, labels=None):
   160                                                   if random.randint(2):
   161                                                       swap = self.perms[random.randint(len(self.perms))]
   162                                                       shuffle = SwapChannels(swap)  # shuffle channels
   163                                                       image = shuffle(image)
   164                                                   return image, boxes, labels

Total time: 0 s
File: /mnt/sdc1/yanleizhang/workspace/pytorch_projects/ssd.pytorch/utils/augmentations.py
Function: __call__ at line 172

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   172                                               @profile
   173                                               def __call__(self, image, boxes=None, labels=None):
   174                                                   if self.current == 'BGR' and self.transform == 'HSV':
   175                                                       image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
   176                                                   elif self.current == 'HSV' and self.transform == 'BGR':
   177                                                       image = cv2.cvtColor(image, cv2.COLOR_HSV2BGR)
   178                                                   else:
   179                                                       raise NotImplementedError
   180                                                   return image, boxes, labels

Total time: 0 s
File: /mnt/sdc1/yanleizhang/workspace/pytorch_projects/ssd.pytorch/utils/augmentations.py
Function: __call__ at line 190

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   190                                               @profile
   191                                               # expects float image
   192                                               def __call__(self, image, boxes=None, labels=None):
   193                                                   if random.randint(2):
   194                                                       alpha = random.uniform(self.lower, self.upper)
   195                                                       image *= alpha
   196                                                   return image, boxes, labels

Total time: 0 s
File: /mnt/sdc1/yanleizhang/workspace/pytorch_projects/ssd.pytorch/utils/augmentations.py
Function: __call__ at line 205

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   205                                               @profile
   206                                               def __call__(self, image, boxes=None, labels=None):
   207                                                   if random.randint(2):
   208                                                       delta = random.uniform(-self.delta, self.delta)
   209                                                       image += delta
   210                                                   return image, boxes, labels

Total time: 0 s
File: /mnt/sdc1/yanleizhang/workspace/pytorch_projects/ssd.pytorch/utils/augmentations.py
Function: __call__ at line 214

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   214                                               @profile
   215                                               def __call__(self, tensor, boxes=None, labels=None):
   216                                                   return tensor.cpu().numpy().astype(np.float32).transpose((1, 2, 0)), boxes, labels

Total time: 0 s
File: /mnt/sdc1/yanleizhang/workspace/pytorch_projects/ssd.pytorch/utils/augmentations.py
Function: __call__ at line 220

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   220                                               @profile
   221                                               def __call__(self, cvimage, boxes=None, labels=None):
   222                                                   return torch.from_numpy(cvimage.astype(np.float32)).permute(2, 0, 1), boxes, labels

Total time: 0 s
File: /mnt/sdc1/yanleizhang/workspace/pytorch_projects/ssd.pytorch/utils/augmentations.py
Function: __call__ at line 252

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   252                                               @profile
   253                                               def __call__(self, image, boxes=None, labels=None):
   254                                                   height, width, _ = image.shape
   255                                                   while True:
   256                                                       # randomly choose a mode
   257                                                       mode = random.choice(self.sample_options)
   258                                                       if mode is None:
   259                                                           return image, boxes, labels
   260                                           
   261                                                       min_iou, max_iou = mode
   262                                                       if min_iou is None:
   263                                                           min_iou = float('-inf')
   264                                                       if max_iou is None:
   265                                                           max_iou = float('inf')
   266                                           
   267                                                       # max trails (50)
   268                                                       for _ in range(50):
   269                                                           current_image = image
   270                                           
   271                                                           w = random.uniform(0.3 * width, width)
   272                                                           h = random.uniform(0.3 * height, height)
   273                                           
   274                                                           # aspect ratio constraint b/t .5 & 2
   275                                                           if h / w < 0.5 or h / w > 2:
   276                                                               continue
   277                                           
   278                                                           left = random.uniform(width - w)
   279                                                           top = random.uniform(height - h)
   280                                           
   281                                                           # convert to integer rect x1,y1,x2,y2
   282                                                           rect = np.array(
   283                                                               [int(left), int(top), int(left + w), int(top + h)])
   284                                           
   285                                                           # calculate IoU (jaccard overlap) b/t the cropped and gt boxes
   286                                                           overlap = jaccard_numpy(boxes, rect)
   287                                           
   288                                                           # is min and max overlap constraint satisfied? if not try again
   289                                                           if overlap.min() < min_iou and max_iou < overlap.max():
   290                                                               continue
   291                                           
   292                                                           # cut the crop from the image
   293                                                           current_image = current_image[rect[1]:rect[3], rect[0]:rect[2],
   294                                                                                         :]
   295                                           
   296                                                           # keep overlap with gt box IF center in sampled patch
   297                                                           centers = (boxes[:, :2] + boxes[:, 2:]) / 2.0
   298                                           
   299                                                           # mask in all gt boxes that above and to the left of centers
   300                                                           m1 = (rect[0] < centers[:, 0]) * (rect[1] < centers[:, 1])
   301                                           
   302                                                           # mask in all gt boxes that under and to the right of centers
   303                                                           m2 = (rect[2] > centers[:, 0]) * (rect[3] > centers[:, 1])
   304                                           
   305                                                           # mask in that both m1 and m2 are true
   306                                                           mask = m1 * m2
   307                                           
   308                                                           # have any valid boxes? try again if not
   309                                                           if not mask.any():
   310                                                               continue
   311                                           
   312                                                           # take only matching gt boxes
   313                                                           current_boxes = boxes[mask, :].copy()
   314                                           
   315                                                           # take only matching gt labels
   316                                                           current_labels = labels[mask]
   317                                           
   318                                                           # should we use the box left and top corner or the crop's
   319                                                           current_boxes[:, :2] = np.maximum(current_boxes[:, :2],
   320                                                                                             rect[:2])
   321                                                           # adjust to crop (by substracting crop's left,top)
   322                                                           current_boxes[:, :2] -= rect[:2]
   323                                           
   324                                                           current_boxes[:, 2:] = np.minimum(current_boxes[:, 2:],
   325                                                                                             rect[2:])
   326                                                           # adjust to crop (by substracting crop's left,top)
   327                                                           current_boxes[:, 2:] -= rect[:2]
   328                                           
   329                                                           return current_image, current_boxes, current_labels

Total time: 0 s
File: /mnt/sdc1/yanleizhang/workspace/pytorch_projects/ssd.pytorch/utils/augmentations.py
Function: __call__ at line 336

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   336                                               @profile
   337                                               def __call__(self, image, boxes, labels):
   338                                                   if random.randint(2):
   339                                                       return image, boxes, labels
   340                                           
   341                                                   height, width, depth = image.shape
   342                                                   ratio = random.uniform(1, 4)
   343                                                   left = random.uniform(0, width * ratio - width)
   344                                                   top = random.uniform(0, height * ratio - height)
   345                                           
   346                                                   expand_image = np.zeros(
   347                                                       (int(height * ratio), int(width * ratio), depth),
   348                                                       dtype=image.dtype)
   349                                                   expand_image[:, :, :] = self.mean
   350                                                   expand_image[int(top):int(top + height),
   351                                                                int(left):int(left + width)] = image
   352                                                   image = expand_image
   353                                           
   354                                                   boxes = boxes.copy()
   355                                                   boxes[:, :2] += (int(left), int(top))
   356                                                   boxes[:, 2:] += (int(left), int(top))
   357                                           
   358                                                   return image, boxes, labels

Total time: 0 s
File: /mnt/sdc1/yanleizhang/workspace/pytorch_projects/ssd.pytorch/utils/augmentations.py
Function: __call__ at line 362

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   362                                               @profile
   363                                               def __call__(self, image, boxes, classes):
   364                                                   _, width, _ = image.shape
   365                                                   if random.randint(2):
   366                                                       image = image[:, ::-1]
   367                                                       boxes = boxes.copy()
   368                                                       boxes[:, 0::2] = width - boxes[:, 2::-2]
   369                                                   return image, boxes, classes

Total time: 0 s
File: /mnt/sdc1/yanleizhang/workspace/pytorch_projects/ssd.pytorch/utils/augmentations.py
Function: __call__ at line 383

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   383                                               @profile
   384                                               def __call__(self, image):
   385                                                   """
   386                                                   Args:
   387                                                       image (Tensor): image tensor to be transformed
   388                                                   Return:
   389                                                       a tensor with channels swapped according to swap
   390                                                   """
   391                                                   # if torch.is_tensor(image):
   392                                                   #     image = image.data.cpu().numpy()
   393                                                   # else:
   394                                                   #     image = np.array(image)
   395                                                   image = image[:, :, self.swaps]
   396                                                   return image

Total time: 0 s
File: /mnt/sdc1/yanleizhang/workspace/pytorch_projects/ssd.pytorch/utils/augmentations.py
Function: __call__ at line 412

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   412                                               @profile
   413                                               def __call__(self, image, boxes, labels):
   414                                                   im = image.copy()
   415                                                   im, boxes, labels = self.rand_brightness(im, boxes, labels)
   416                                                   if random.randint(2):
   417                                                       distort = Compose(self.pd[:-1])
   418                                                   else:
   419                                                       distort = Compose(self.pd[1:])
   420                                                   im, boxes, labels = distort(im, boxes, labels)
   421                                                   return self.rand_light_noise(im, boxes, labels)

Total time: 7.4e-05 s
File: /mnt/sdc1/yanleizhang/workspace/pytorch_projects/ssd.pytorch/utils/augmentations.py
Function: __init__ at line 425

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   425                                               @profile
   426                                               def __init__(self, size=300, mean=(104, 117, 123)):
   427         1          1.0      1.0      1.4          self.mean = mean
   428         1          1.0      1.0      1.4          self.size = size
   429         1          0.0      0.0      0.0          self.augment = Compose([
   430         1          0.0      0.0      0.0              ConvertFromInts(),
   431         1          1.0      1.0      1.4              ToAbsoluteCoords(),
   432         1         30.0     30.0     40.5              PhotometricDistort(),
   433         1          3.0      3.0      4.1              Expand(self.mean),
   434         1          5.0      5.0      6.8              RandomSampleCrop(),
   435         1          1.0      1.0      1.4              RandomMirror(),
   436         1          1.0      1.0      1.4              ToPercentCoords(),
   437         1          2.0      2.0      2.7              Resize(self.size),
   438         1         29.0     29.0     39.2              SubtractMeans(self.mean)
   439                                                   ])

Total time: 0 s
File: /mnt/sdc1/yanleizhang/workspace/pytorch_projects/ssd.pytorch/utils/augmentations.py
Function: __call__ at line 441

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   441                                               @profile
   442                                               def __call__(self, img, boxes, labels):
   443                                                   return self.augment(img, boxes, labels)

Total time: 257.426 s
File: train.py
Function: train at line 71

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    71                                           @profile
    72                                           def train():
    73         1          4.0      4.0      0.0      if args.dataset == 'COCO':
    74                                                   if args.dataset_root == VOC_ROOT:
    75                                                       if not os.path.exists(COCO_ROOT):
    76                                                           parser.error('Must specify dataset_root if specifying dataset')
    77                                                       print("WARNING: Using default COCO dataset_root because " +
    78                                                             "--dataset_root was not specified.")
    79                                                       args.dataset_root = COCO_ROOT
    80                                                   cfg = coco
    81                                                   dataset = COCODetection(root=args.dataset_root,
    82                                                                           transform=SSDAugmentation(cfg['min_dim'],
    83                                                                                                     MEANS))
    84         1          3.0      3.0      0.0      elif args.dataset == 'VOC':
    85         1          2.0      2.0      0.0          if args.dataset_root == COCO_ROOT:
    86                                                       parser.error('Must specify dataset if specifying dataset_root')
    87         1          2.0      2.0      0.0          cfg = voc
    88         1          2.0      2.0      0.0          dataset = VOCDetection(root=args.dataset_root,
    89         1          3.0      3.0      0.0                                 transform=SSDAugmentation(cfg['min_dim'],
    90         1      15847.0  15847.0      0.0                                                           MEANS))
    91                                           
    92         1          4.0      4.0      0.0      if args.visdom:
    93                                                   import visdom
    94                                                   viz = visdom.Visdom()
    95                                           
    96         1   12534460.0 12534460.0      4.9      ssd_net = build_ssd('train', cfg['min_dim'], cfg['num_classes'])
    97         1          4.0      4.0      0.0      net = ssd_net
    98                                           
    99         1         10.0     10.0      0.0      if args.cuda:
   100         1        151.0    151.0      0.0          net = torch.nn.DataParallel(ssd_net)
   101         1          8.0      8.0      0.0          cudnn.benchmark = False
   102                                           
   103         1          3.0      3.0      0.0      if args.resume:
   104                                                   print('Resuming training, loading {}...'.format(args.resume))
   105                                                   ssd_net.load_weights(args.resume)
   106                                               else:
   107         1    2382688.0 2382688.0      0.9          vgg_weights = torch.load(args.save_folder + args.basenet)
   108         1         64.0     64.0      0.0          print('Loading base network...')
   109         1     133763.0 133763.0      0.1          ssd_net.vgg.load_state_dict(vgg_weights)
   110                                           
   111         1         97.0     97.0      0.0      if args.cuda:
   112         1       1147.0   1147.0      0.0          net = net.cuda()
   113                                           
   114         1          4.0      4.0      0.0      if not args.resume:
   115         1         35.0     35.0      0.0          print('Initializing weights...')
   116                                                   # initialize newly added layers' weights with xavier method
   117         1        637.0    637.0      0.0          ssd_net.extras.apply(weights_init)
   118         1        204.0    204.0      0.0          ssd_net.loc.apply(weights_init)
   119         1        206.0    206.0      0.0          ssd_net.conf.apply(weights_init)
   120                                           
   121         1         13.0     13.0      0.0      optimizer = optim.SGD(net.parameters(), lr=args.lr, momentum=args.momentum,
   122         1        990.0    990.0      0.0                            weight_decay=args.weight_decay)
   123         1         19.0     19.0      0.0      criterion = MultiBoxLoss(cfg['num_classes'], 0.5, True, 0, True, 3, 0.5,
   124         1        151.0    151.0      0.0                               False, args.cuda)
   125                                           
   126         1        704.0    704.0      0.0      net.train()
   127                                               # loss counters
   128         1          3.0      3.0      0.0      loc_loss = 0
   129         1          2.0      2.0      0.0      conf_loss = 0
   130         1          2.0      2.0      0.0      epoch = 0
   131         1         13.0     13.0      0.0      print('Loading the dataset...')
   132                                           
   133         1         53.0     53.0      0.0      epoch_size = len(dataset) // args.batch_size
   134         1         10.0     10.0      0.0      print('Training SSD on:', dataset.name)
   135         1          6.0      6.0      0.0      print('Using the specified args:')
   136         1        136.0    136.0      0.0      print(args)
   137                                           
   138         1          3.0      3.0      0.0      step_index = 0
   139                                           
   140         1          3.0      3.0      0.0      if args.visdom:
   141                                                   vis_title = 'SSD.PyTorch on ' + dataset.name
   142                                                   vis_legend = ['Loc Loss', 'Conf Loss', 'Total Loss']
   143                                                   iter_plot = create_vis_plot('Iteration', 'Loss', vis_title, vis_legend)
   144                                                   epoch_plot = create_vis_plot('Epoch', 'Loss', vis_title, vis_legend)
   145                                           
   146         1          6.0      6.0      0.0      data_loader = data.DataLoader(dataset, args.batch_size,
   147         1          3.0      3.0      0.0                                    num_workers=args.num_workers,
   148         1          3.0      3.0      0.0                                    shuffle=True, collate_fn=detection_collate,
   149         1         57.0     57.0      0.0                                    pin_memory=True)
   150                                               # create batch iterator
   151         1     145443.0 145443.0      0.1      batch_iterator = iter(data_loader)
   152       101        407.0      4.0      0.0      for iteration in range(args.start_iter, cfg['max_iter']):
   153       100        339.0      3.4      0.0          if args.visdom and iteration != 0 and (iteration % epoch_size == 0):
   154                                                       update_vis_plot(epoch, loc_loss, conf_loss, epoch_plot, None,
   155                                                                       'append', epoch_size)
   156                                                       # reset epoch loss counters
   157                                                       loc_loss = 0
   158                                                       conf_loss = 0
   159                                                       epoch += 1
   160                                           
   161       100        528.0      5.3      0.0          if iteration in cfg['lr_steps']:
   162                                                       step_index += 1
   163                                                       adjust_learning_rate(optimizer, args.gamma, step_index)
   164                                           
   165                                                   # load train data
   166                                                   # images, targets = next(batch_iterator)
   167                                           
   168       100        341.0      3.4      0.0          try:
   169       100    2171572.0  21715.7      0.8              images, targets = next(batch_iterator)
   170                                                   except StopIteration:
   171                                                       batch_iterator = iter(data_loader)
   172                                                       images, targets = next(batch_iterator)
   173                                           
   174       100        498.0      5.0      0.0          if args.cuda:
   175       100     569163.0   5691.6      0.2              images = Variable(images.cuda())
   176       100     292490.0   2924.9      0.1              targets = [Variable(ann.cuda(), volatile=True) for ann in targets]
   177                                                   else:
   178                                                       images = Variable(images)
   179                                                       targets = [Variable(ann, volatile=True) for ann in targets]
   180                                                   # forward
   181       100        834.0      8.3      0.0          t0 = time.time()
   182       100  120022445.0 1200224.4     46.6          out = net(images)
   183                                                   # backprop
   184       100      97262.0    972.6      0.0          optimizer.zero_grad()
   185       100   66142678.0 661426.8     25.7          loss_l, loss_c = criterion(out, targets)
   186       100     127005.0   1270.0      0.0          loss = loss_l + loss_c
   187       100    4666327.0  46663.3      1.8          loss.backward()
   188       100     398613.0   3986.1      0.2          optimizer.step()
   189       100        924.0      9.2      0.0          t1 = time.time()
   190       100   47399700.0 473997.0     18.4          loc_loss += loss_l.data[0]
   191       100      11103.0    111.0      0.0          conf_loss += loss_c.data[0]
   192                                           
   193       100        613.0      6.1      0.0          if iteration % 10 == 0:
   194        10       1085.0    108.5      0.0              print('timer: %.4f sec.' % (t1 - t0))
   195        10         92.0      9.2      0.0              print('iter ' + repr(iteration) + ' || Loss: %.4f ||' %
   196        10        661.0     66.1      0.0                    (loss.data[0]), end=' ')
   197                                           
   198       100       1124.0     11.2      0.0          if args.visdom:
   199                                                       update_vis_plot(iteration, loss_l.data[0], loss_c.data[0],
   200                                                                       iter_plot, epoch_plot, 'append')
   201                                           
   202       100        424.0      4.2      0.0          if iteration != 0 and iteration % 5000 == 0:
   203                                                       print('Saving state, iter:', iteration)
   204                                                       torch.save(ssd_net.state_dict(), 'weights/ssd300_COCO_' +
   205                                                                  repr(iteration) + '.pth')
   206         1        667.0    667.0      0.0      torch.save(ssd_net.state_dict(),
   207         1     302464.0 302464.0      0.1                 args.save_folder + '' + args.dataset + '.pth')

Total time: 0 s
File: train.py
Function: adjust_learning_rate at line 210

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   210                                           @profile
   211                                           def adjust_learning_rate(optimizer, gamma, step):
   212                                               """Sets the learning rate to the initial LR decayed by 10 at every
   213                                                   specified step
   214                                               # Adapted from PyTorch Imagenet example:
   215                                               # https://github.com/pytorch/examples/blob/master/imagenet/main.py
   216                                               """
   217                                               lr = args.lr * (gamma ** (step))
   218                                               for param_group in optimizer.param_groups:
   219                                                   param_group['lr'] = lr

